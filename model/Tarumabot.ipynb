{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "view-in-github",
   "metadata": {
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/fendy07/chatbot-AI/blob/master/DL_Chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18e160a",
   "metadata": {
    "id": "d18e160a"
   },
   "source": [
    "# **Chatbot Using Long Short Term Memory Algorithm**\n",
    "\n",
    "Sumber code: [Medium - Going Merry With Tensorflow 2.0](https://medium.com/analytics-vidhya/chatbot-with-tensorflow-2-0-going-merry-2f79284a6104)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MZMVLNyqYTCK",
   "metadata": {
    "id": "MZMVLNyqYTCK"
   },
   "source": [
    "# **Import Library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df6e6af3",
   "metadata": {
    "id": "df6e6af3"
   },
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import json\n",
    "import nltk\n",
    "import time\n",
    "import random\n",
    "import string\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "import tensorflow as tf\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.utils import plot_model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Flatten, Dense, GlobalMaxPool1D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XFqXivzfTGhq",
   "metadata": {
    "id": "XFqXivzfTGhq"
   },
   "source": [
    "## **Download NLTK Package**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ZFHfBZ3mO1QE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZFHfBZ3mO1QE",
    "outputId": "35b611b0-a04b-4ad6-9ab9-021cc696dd5a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Package sentence tokenizer\n",
    "nltk.download('punkt')\n",
    "# Package lemmatization\n",
    "nltk.download('wordnet')\n",
    "# Package multilingual wordnet data\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gLGpuyY9aMwW",
   "metadata": {
    "id": "gLGpuyY9aMwW"
   },
   "source": [
    "# **Load Dataset Json**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "JD4ILKqFZ_hf",
   "metadata": {
    "id": "JD4ILKqFZ_hf"
   },
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "with open('data.json', encoding='utf-8') as content:\n",
    "  data1 = json.load(content)\n",
    "\n",
    "# Mendapatkan semua data ke dalam list\n",
    "tags = [] # data tag\n",
    "inputs = [] # data input atau pattern\n",
    "responses = {} # data respon\n",
    "words = [] # Data kata\n",
    "classes = [] # Data Kelas atau Tag\n",
    "documents = [] # Data Kalimat Dokumen\n",
    "ignore_words = ['?', '!'] # Mengabaikan tanda spesial karakter\n",
    "# Tambahkan data intents dalam json\n",
    "for intent in data1['intents']:\n",
    "  responses[intent['tag']]=intent['responses']\n",
    "  for lines in intent['patterns']:\n",
    "    inputs.append(lines)\n",
    "    tags.append(intent['tag'])\n",
    "    # digunakan untuk pattern atau teks pertanyaan dalam json\n",
    "    for pattern in intent['patterns']:\n",
    "      w = nltk.word_tokenize(pattern)\n",
    "      words.extend(w)\n",
    "      documents.append((w, intent['tag']))\n",
    "      # tambahkan ke dalam list kelas dalam data\n",
    "      if intent['tag'] not in classes:\n",
    "        classes.append(intent['tag'])\n",
    "\n",
    "# Konversi data json ke dalam dataframe\n",
    "data = pd.DataFrame({\"patterns\":inputs, \"tags\":tags})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5N0s7BObcv5-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "5N0s7BObcv5-",
    "outputId": "ffefb3ae-1192-4b84-dcdb-3093bded2e48"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patterns</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hallo</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hai kak</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>helo</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hai</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>halo</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1827</th>\n",
       "      <td>Untar punya wakil rektor siapa sih?</td>\n",
       "      <td>wakil_rektor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1828</th>\n",
       "      <td>Jabatan wakil rektor di Untar dipegang siapa?</td>\n",
       "      <td>wakil_rektor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1829</th>\n",
       "      <td>Siapa yang jadi wakil rektor Untar sekarang?</td>\n",
       "      <td>wakil_rektor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1830</th>\n",
       "      <td>Informasi wakil rektor Untar siapa?</td>\n",
       "      <td>wakil_rektor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1831</th>\n",
       "      <td>Siapa wakil rektor I di Untar?</td>\n",
       "      <td>wakil_rektor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1832 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           patterns          tags\n",
       "0                                             hallo      greeting\n",
       "1                                           Hai kak      greeting\n",
       "2                                              helo      greeting\n",
       "3                                               hai      greeting\n",
       "4                                              halo      greeting\n",
       "...                                             ...           ...\n",
       "1827            Untar punya wakil rektor siapa sih?  wakil_rektor\n",
       "1828  Jabatan wakil rektor di Untar dipegang siapa?  wakil_rektor\n",
       "1829   Siapa yang jadi wakil rektor Untar sekarang?  wakil_rektor\n",
       "1830            Informasi wakil rektor Untar siapa?  wakil_rektor\n",
       "1831                 Siapa wakil rektor I di Untar?  wakil_rektor\n",
       "\n",
       "[1832 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cetak data keseluruhan\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5DFoJwcVdP52",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "5DFoJwcVdP52",
    "outputId": "6ae78a83-79fe-4ce4-9ffb-63c9a6b6fbf7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patterns</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hallo</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hai kak</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>helo</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hai</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>halo</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  patterns      tags\n",
       "0    hallo  greeting\n",
       "1  Hai kak  greeting\n",
       "2     helo  greeting\n",
       "3      hai  greeting\n",
       "4     halo  greeting"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cetak data baris pertama sampai baris kelima\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vHnr2WFvebeJ",
   "metadata": {
    "id": "vHnr2WFvebeJ"
   },
   "source": [
    "# **Preprocessing The Data**\n",
    "\n",
    "1.   Remove Punctuations (Menghapus Punktuasi)\n",
    "2.   Lematization (Lematisasi)\n",
    "3.   Tokenization (Tokenisasi)\n",
    "4.   Apply Padding (Padding)\n",
    "5.   Encoding the Outputs (Konversi Keluaran Enkoding)\n",
    "\n",
    "Kelima tahapan pemrosesan teks ini dijelaskan pada bagian langkah selanjutnya."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "u_04NeXTIImg",
   "metadata": {
    "id": "u_04NeXTIImg"
   },
   "source": [
    "## **Remove Punctuations**\n",
    "\n",
    "Tahapan praproses pada data teks yang pertama adalah menghapus punktuasi atau tanda baca seperti *special character* yaitu **'!'** (**tanda seru**) **','** (**tanda koma**) **'.'** (**tanda titik sebagai berhenti**) '**?**' (**tanda tanya**) dan tanda baca yang lain. Tahapan ini gunanya untuk mempermudah pemrosesan data teks yang akan kita olah."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "Gh-7EtrfhQgY",
   "metadata": {
    "id": "Gh-7EtrfhQgY"
   },
   "outputs": [],
   "source": [
    "# Removing Punctuations (Menghilangkan Punktuasi)\n",
    "data['patterns'] = data['patterns'].apply(lambda wrd:[ltrs.lower() for ltrs in wrd if ltrs not in string.punctuation])\n",
    "data['patterns'] = data['patterns'].apply(lambda wrd: ''.join(wrd))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5brR-qBLJDa_",
   "metadata": {
    "id": "5brR-qBLJDa_"
   },
   "source": [
    "## **Lemmatization (Lematisasi)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22MVRGBsO9gX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "22MVRGBsO9gX",
    "outputId": "3667b855-d300-4c61-a7be-435bc985ac57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "981 unique lemmatized words ['(', ')', ',', '2024/2025', '24', '4.0', '[', 'a', 'acara', 'acara-acara', 'ada', 'adain', 'administrasi', 'afternoon', 'agama', 'agar', 'aja', 'ajaran', 'ajukan', 'ak', 'akademik', 'akhir', 'akhir-akhir', 'akreditasi', 'aktif', 'alamat', 'almamater', 'almameter', 'altar', 'alumni-alumni', 'alumnus', 'alur', 'alurnya', 'ambil', 'anggota', 'angka', 'antar', 'antara', 'apa', 'apakah', 'apasih', 'aplikasi', 'arah', 'area', 'artis', 'asia', 'aspek', 'asrama', 'atas', 'atau', 'aturan', 'auditorium', 'awal', 'b', 'baca', 'badan', 'bagaimana', 'bagi', 'bagian', 'bagus', 'baik', 'bakat', 'ban-pt', 'bank', 'bantu', 'bantuan', 'banyak', 'bareng', 'barengan', 'baru', 'batal', 'batalin', 'bawa', 'bay', 'bayar', 'beasiswa', 'beberapa', 'beda', 'bedanya', 'bekerja', 'belajar', 'belajar-mengajarnya', 'belakang', 'belum', 'bem', 'bentuk', 'berada', 'beradaptasi', 'berakhir', 'berakhirnya', 'berapa', 'berbagai', 'berbasis', 'berbeda', 'berdampak', 'berdasarkan', 'berdiri', 'berdirinya', 'berfokus', 'bergabung', 'berhenti', 'berkarier', 'berkas', 'berkas-berkas', 'berkembang', 'berkontribusi', 'berkualitas', 'berlangsung', 'berlokasi', 'beroperasi', 'berpartisipasi', 'berprestasi', 'bersaing', 'bersama', 'bersamaan', 'bersih', 'bertingkat', 'bertugas', 'berubah', 'berupa', 'bervariasi', 'berwirausaha', 'besar', 'biar', 'biasanya', 'biaya', 'bidang', 'bikin', 'bisa', 'bisakah', 'bisnis', 'boleh', 'bro', 'buat', 'buddha', 'buka', 'bukan', 'bulan', 'bursa', 'buta', 'butuh', 'bye', 'byee', 'cafe', 'calon', 'cara', 'caranya', 'cari', 'cctv', 'cctv-nya', 'cek', 'cepat', 'ciri', 'citra', 'co-working', 'cocok', 'college', 'cukup', 'cuma', 'cuti', 'dadah', 'daerah', 'daftar', 'dah', 'dahulu', 'dalam', 'dan', 'dana', 'dapat', 'dapet', 'dapetin', 'dari', 'darurat', 'daya', 'dengan', 'depan', 'desain', 'detail', 'di', 'di-update', 'diadain', 'diadakan', 'diakses', 'diakui', 'diambil', 'dibanding', 'dibandingkan', 'dibantu', 'dibawa', 'dibayar', 'dibayarkan', 'diberikan', 'dibuat', 'dibuka', 'dibutuhin', 'dibutuhkan', 'dicapai', 'dicek', 'dicicil', 'didapet', 'didirikan', 'didirikannya', 'didukung', 'digital', 'digitalisasi', 'digunakan', 'dihubungkan', 'diikuti', 'diikutin', 'diintegrasikan', 'dijaga', 'dikembaliin', 'dikembalikan', 'dikenakan', 'dikenal', 'dikumpulin', 'dikumpulkan', 'dilaksanakan', 'dilakuin', 'dilakukan', 'dilengkapi', 'dilihat', 'dilunasi', 'dimaksud', 'dimana', 'dimiliki', 'dimulai', 'dipakai', 'dipegang', 'dipenuhi', 'diperbarui', 'diperlukan', 'diperoleh', 'dipilih', 'diraih', 'diri', 'disediain', 'disediakan', 'diselesaikan', 'diserahkan', 'disesuaikan', 'disiapin', 'disiapkan', 'diskusi', 'ditawarkan', 'ditentukan', 'diterima', 'ditunda', 'diumumin', 'diumumkan', 'diuntar', 'diusung', 'diwajibkan', 'diwisuda', 'doktor', 'doktoral', 'dokumen', 'dokumennya', 'dong', 'dosen', 'dua', 'dua-duanya', 'dukung', 'dukungan', 'dulu', 'dunia', 'durasi', 'e-book', 'e-library', 'ekonomi', 'eksekutif', 'eksternal', 'ekstrakurikuler', 'empat', 'enak', 'era', 'erat', 'estimasi', 'evakuasi', 'evening', 'event', 'exchange', 'fair', 'faktor', 'fakultas', 'fakultas-fakultas', 'farmasi', 'fasilitas', 'fasilitasnya', 'favorit', 'figur', 'finansial', 'fokus', 'fokusnya', 'form', 'format', 'fotografi', 'ga', 'gabung', 'gak', 'gampang', 'ganjil', 'ganti', 'gedung', 'genap', 'gerbang', 'gereja', 'gimana', 'global', 'good', 'goodmorning', 'goodnight', 'gratis', 'gym', 'hadapi', 'hadir', 'hai', 'hallo', 'halo', 'hard', 'harga', 'harganya', 'hari', 'harus', 'hasil', 'hei', 'helo', 'hi', 'hingga', 'hobi', 'hubungan', 'hy', 'i', 'ibadah', 'identitas', 'ikut', 'ikuti', 'indonesia', 'industri', 'info', 'informasi', 'ingin', 'ini', 'inkubator', 'inovasi', 'institusi', 'internal', 'internasional', 'internet', 'itu', 'izinin', 'jabat', 'jabatan', 'jadi', 'jadwal', 'jalan', 'jalur', 'jam', 'jamin', 'jangka', 'jaringan', 'jatuh', 'jawabannya', 'jelasin', 'jelaskan', 'jenis', 'jenis-jenis', 'jenjang', 'jika', 'jiwa', 'job', 'join', 'jpp', 'juara', 'juga', 'jumlah', 'jumpa', 'jurnal', 'jurusan', 'kafe', 'kak', 'kalau', 'kalender', 'kali', 'kalo', 'kamar', 'kampus', 'kampus-kampus', 'kampusnya', 'kamu', 'kanal', 'kancah', 'kantin', 'kantinnya', 'kapan', 'kapasitas', 'karena', 'karier', 'karir', 'kasih', 'kata', 'kawan', 'kayak', 'ke', 'keamanan', 'kebijakan', 'kebugaran', 'kebutuhan', 'kecil', 'kedokteran', 'kedua', 'keduanya', 'kegiatan', 'kehidupan', 'kelas', 'kelas-kelas', 'kelasnya', 'kelebihan', 'kelompok', 'keluar', 'kelulusan', 'kemitraan', 'kemungkinan', 'kenaikan', 'kenapa', 'kendala', 'kendaraan', 'kepada', 'kepala', 'kerja', 'kerjasama', 'kesehatan', 'keseluruhan', 'kesempatan', 'kesiapan', 'kesulitan', 'ketat', 'ketentuan', 'keterampilan', 'keterkaitan', 'keterlibatan', 'ketersediaan', 'keuangan', 'keunggulan', 'keuntungan', 'kewajiban', 'kewirausahaan', 'khas', 'khusus', 'kira-kira', 'kkn', 'kl', 'klinik', 'kolaborasi', 'koleksi', 'kompetisi', 'komponen', 'komunitas', 'kondisi', 'konferensi', 'konseling', 'konselor', 'kontribusi', 'kreatif', 'kualitas', 'kualitasnya', 'kuat', 'kuliah', 'kuliahnya', 'kurikulum', 'kursus', 'lab', 'lab-nya', 'laboratorium', 'laboratoriumnya', 'lagi', 'lain', 'lainnya', 'lakukan', 'lama', 'langkah', 'langkah-langkah', 'langsung', 'lanjut', 'lanjutan', 'laper', 'latar', 'layanan', 'lebih', 'lembaga', 'lengkap', 'letaknya', 'lewat', 'liat', 'libur', 'liburnya', 'lihat', 'lingkungan', 'logo', 'lokasi', 'lokasinya', 'lomba', 'luar', 'luas', 'lulu', 'lulusan', 'lulusannya', 'magang', 'magister', 'mahal', 'mahasiswa', 'mahasiswanya', 'makan', 'makasih', 'malam', 'mana', 'mandi', 'marun', 'masa', 'masalah', 'masih', 'masing-masing', 'masjid', 'masuk', 'masyarakat', 'masyuarakat', 'mata', 'mau', 'mekanisme', 'melaksanakan', 'melakukan', 'melalui', 'melanjutkan', 'melatarbelakangi', 'melibatkan', 'melihat', 'memadai', 'memanfaatkan', 'memastikan', 'memasuki', 'membantu', 'membatalkan', 'membayar', 'membekali', 'memberi', 'memberikan', 'membuat', 'membuka', 'membutuhkan', 'memenuhi', 'memerlukan', 'memfasilitasi', 'memilih', 'memiliki', 'memimpin', 'mempekerjakan', 'mempengaruhi', 'memperbarui', 'memperoleh', 'mempersiapkan', 'memulai', 'memungkinkan', 'memutuskan', 'menampung', 'menang', 'menawarkan', 'mencakup', 'mencari', 'mendaftar', 'mendanai', 'mendapatkan', 'mendirikan', 'mendorong', 'mendukung', 'menemukan', 'menentukan', 'menerima', 'menetapkan', 'mengadakan', 'mengajar', 'mengajukan', 'mengakses', 'mengalami', 'mengambil', 'mengapa', 'mengecek', 'mengembangkan', 'mengetahui', 'menggelar', 'menggunakan', 'menghadapi', 'menghadiri', 'mengikuti', 'mengintegrasikan', 'mengizinkan', 'meningkatkan', 'menjabat', 'menjadi', 'menjadikan', 'menjalin', 'menu', 'menuju', 'menunjang', 'menunjukkan', 'menyalurkan', 'menyediakan', 'menyelenggarakan', 'menyelesaikan', 'menyesuaikan', 'merah', 'merasa', 'merumuskan', 'merupakan', 'mesti', 'metode', 'mewakili', 'milih', 'minat', 'minatnya', 'misi', 'misinya', 'mitra', 'modern', 'morning', 'mula', 'mulai', 'mulainya', 'multimedia', 'naik', 'naikin', 'nama', 'nasional', 'nawarin', 'negeri', 'nemuin', 'ngadain', 'ngadepin', 'ngajarin', 'ngajuin', 'ngambilnya', 'ngapain', 'ngasih', 'ngebantu', 'ngembangin', 'ngerjain', 'nggak', 'ngikutin', 'nilai', 'nilai-nilai', 'ningkatin', 'non-akademik', 'nunda', 'nunjukin', 'nyaman', 'nyata', 'nyediain', 'nyesuain', 'nyiapin', 'offline', 'oke', 'olahraga', 'oleh', 'online', 'opsi', 'organisasi', 'pa', 'pada', 'pagi', 'pakai', 'pake', 'panduan', 'panjang', 'para', 'parkir', 'parkiran', 'parkirnya', 'pascasarjana', 'pekerjaan', 'pelajar', 'pelaksanaan', 'pelatihan', 'peluang', 'pembagian', 'pembaruan', 'pembayaran', 'pembeda', 'pembelajaran', 'pembelajarannya', 'pembentukan', 'pemberian', 'pemberitahuan', 'pembinaan', 'pembuatmu', 'pemeliharaan', 'pemimpin', 'pencapaian', 'pendaftaran', 'pendidikan', 'pendiri', 'pendirian', 'penelitian', 'penempatan', 'penerimaan', 'pengabdian', 'pengajuan', 'pengakuan', 'pengalaman', 'pengambilan', 'pengembalian', 'pengembangan', 'pengen', 'pengguna', 'penggunaan', 'penghargaan', 'pengumuman', 'pengunduran', 'penilaian', 'penjagaan', 'penting', 'penuhi', 'penundaan', 'penunjang', 'penyaluran', 'per', 'peralatan', 'peran', 'perawatan', 'perbandingan', 'perbedaan', 'perekrutan', 'perguruan', 'peringkat', 'periode', 'perjalanan', 'perkembangan', 'perkuliahan', 'perlu', 'pernah', 'perpustakaan', 'persiapan', 'persyaratan', 'pertama', 'pertukaran', 'perubahan', 'perusahaan', 'perusahaan-perusahaan', 'petugas', 'pihak', 'pilih', 'pilihan', 'pimpinan', 'pindah', 'platform', 'populasi', 'portal', 'posisi', 'potensi', 'praktikum', 'prasarana', 'prestasi', 'pribadi', 'prodi', 'profesional', 'program', 'programnya', 'prose', 'prosedur', 'prosesnya', 'proyek', 'psikotes', 'ptn', 'publik', 'punya', 'pusat', 'rata-rata', 'registrasi', 'reguler', 'rekrutmen', 'rektor', 'relevan', 'reputasi', 'reputasinya', 'resmi', 'restoran', 'revolusi', 'ribet', 'rincian', 'riset', 'roda', 'ruang', 'ruangan', 'rupa', 'rutin', 's2', 's3', 'saat', 'saja', 'salah', 'sama', 'sampai', 'sanksi', 'sarana', 'satpam', 'satu', 'saya', 'sebagai', 'sebelum', 'seberapa', 'secara', 'see', 'sehari-hari', 'seharian', 'sejak', 'sejarah', 'sejauh', 'sekaligus', 'sekarang', 'sekolah', 'sektor', 'selalu', 'selama', 'selamat', 'selanjutnya', 'selebriti', 'seleksi', 'selesai', 'seluruh', 'semester', 'seminar', 'semua', 'sendiri', 'seni', 'sepanjang', 'seperti', 'seragam', 'serbaguna', 'sering', 'sertifikasi', 'sesi', 'sesuai', 'setahun', 'setelah', 'setiap', 'setingkat', 'si', 'sia', 'siang', 'siap', 'siap-siap', 'siapa', 'sih', 'simbolis', 'simbolisnya', 'sistem', 'skill', 'skripsi', 'soal', 'soft', 'sore', 'spp', 'staf', 'standar', 'startup', 'status', 'stikes', 'strategi', 'student', 'studi', 'studio', 'sudah', 'suka', 'sumbangan', 'sumber', 'supaya', 'support', 'susah', 'syarat', 'tahapan', 'tahu', 'tahun', 'tahunnya', 'tambahan', 'tanggal', 'tanggap', 'tanpa', 'tantangan', 'tarif', 'tarumabot', 'tarumanagara', 'tata', 'tau', 'te', 'teknik', 'teknologi', 'telah', 'tempat', 'tentang', 'terawat', 'terbaik', 'terbaru', 'terbuka', 'tercermin', 'terdaftar', 'terdapat', 'tergantung', 'terhadap', 'terhubung', 'terima', 'terimakasih', 'terintegrasi', 'terkait', 'terkenal', 'terkini', 'terlebih', 'terletak', 'terlibat', 'termasuk', 'tersebut', 'tersedia', 'terstruktur', 'tertarik', 'tertentu', 'tertinggi', 'terus', 'thank', 'thanks', 'thankyou', 'tiap', 'tidak', 'tinggal', 'tinggi', 'tingkat', 'toilet', 'tokoh', 'total', 'transfer', 'tren', 'tugas', 'tujuan', 'tunda', 'tunggal', 'tunjukin', 'uang', 'udah', 'ujian', 'ukm', 'ukm-nya', 'ukt', 'ulang', 'unggul', 'unggulan', 'unit', 'universitas', 'untar', 'untuk', 'up-to-date', 'upaya', 'update', 'usaha', 'usia', 'usm', 'utama', 'variasi', 'visi', 'wadah', 'wajib', 'wakil', 'waktu', 'waktunya', 'warna', 'warnanya', 'wi-fi', 'wifi', 'wilayah', 'wirausaha', 'wisuda', 'workshop', 'xinya', 'ya', 'yang', 'you']\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "words = [lemmatizer.lemmatize(w.lower()) for w in words if w not in ignore_words]\n",
    "words = sorted(list(set(words)))\n",
    "\n",
    "print (len(words), \"unique lemmatized words\", words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zmZpqovQE1Zb",
   "metadata": {
    "id": "zmZpqovQE1Zb"
   },
   "source": [
    "### **Menyortir Data Kelas Tags**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "TK_v4Zw5P8rn",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TK_v4Zw5P8rn",
    "outputId": "b18bb102-ad76-423f-a688-7baf7fb9fdf7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91 classes ['alamat_untar', 'alumni_terkenal', 'alur_pendaftaran', 'asrama_mahasiswa', 'beasiswa_berprestasi', 'beasiswa_untar', 'berdirinya_untar', 'biaya_kuliah', 'cara_membayar_spp', 'dispensasi_biaya', 'dokumen_yang_diperlukan', 'dukungan_kompetisi', 'event_job_fair', 'fakultas_untar', 'farewell', 'fasilitas_ibadah', 'fasilitas_kamarmandi', 'fasilitas_kesehatan', 'fasilitas_layanan_konseling', 'fasilitas_olahraga', 'fasilitas_parkir', 'fasilitas_perpustakaan', 'fasilitas_untar', 'fasilitas_wifi', 'greeting', 'hasil_seleksi', 'hubungan_dunia_industri', 'identitas_untar', 'jadwal_kuliah', 'jadwal_ujian', 'jadwal_wisuda', 'jumlah_mahasiswa', 'kantin_untar', 'kelebihan_untar', 'kerjasama_beasiswa', 'kerjasama_magang', 'kerjasama_rekrutmen', 'kompetisi_internal', 'komponen_biaya', 'kualitas_laboratorium', 'kualitas_ruang_kelas', 'kurikulum_universitas', 'libur_semester', 'magang_kurikulum', 'menghadapi_dunia_kerja', 'nilai_kuliah', 'organisasi_daftar', 'organisasi_minatdanbakat', 'pascasarjana_doktoral', 'pelatihan_keterampilan', 'pencipta_tarumabot', 'penerimaan_jalur_prestasi', 'pengabdian_dosen_untar', 'pengembalian_biaya_spp', 'pengembangan_kewirausahaan', 'penghargaan_untar', 'peran_alumni', 'peran_bem', 'peran_untar_untuk_mahasiswa', 'periode_semester_ganjil', 'periode_semester_genap', 'perpustakaan_digital', 'perubahan_biaya_kuliah', 'prestasi_mahasiswa_untar', 'program_kkn', 'program_pertukaran_mahasiswa', 'program_studi', 'prosedur_cuti', 'prosedur_pendaftaran_ulang', 'prosedur_pengajuan_wisuda', 'prosedur_pindah_jurusan', 'psikotes_fakultas_kedokteran', 'rektor_untar', 'reputasi_untar', 'revolusi_industri', 'ruang_auditorium', 'ruang_belajar_bersama', 'sejarah_berdirinya_untar', 'sistem_keamanan', 'stikes_tarumanagara', 'studio_seni', 'syarat_kelulusan', 'tarumabot', 'tes_buta_warna', 'ukm_untar', 'untar_bem', 'usm_jpp', 'visi_misi_untar', 'wakil_rektor', 'waktu_pendaftaran_ulang', 'xinya_college']\n"
     ]
    }
   ],
   "source": [
    "# sorting pada data class\n",
    "classes = sorted(list(set(classes)))\n",
    "print (len(classes), \"classes\", classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sVdv1gW5N7a6",
   "metadata": {
    "id": "sVdv1gW5N7a6"
   },
   "source": [
    "## **Tokenization (Tokenisasi)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "Xr5aehymeQdi",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xr5aehymeQdi",
    "outputId": "76c6632d-34ae-46ed-b6fa-d5464ee9a786"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[697],\n",
       " [513, 698],\n",
       " [699],\n",
       " [513],\n",
       " [342],\n",
       " [700],\n",
       " [701],\n",
       " [702],\n",
       " [703],\n",
       " [704],\n",
       " [705],\n",
       " [438],\n",
       " [234, 438],\n",
       " [706],\n",
       " [707],\n",
       " [439],\n",
       " [234, 439],\n",
       " [514],\n",
       " [440, 514],\n",
       " [441],\n",
       " [234, 441],\n",
       " [515],\n",
       " [440, 515],\n",
       " [442],\n",
       " [234, 442],\n",
       " [342, 234, 438],\n",
       " [342, 234, 439],\n",
       " [342, 234, 441],\n",
       " [342, 234, 442],\n",
       " [4, 84, 343],\n",
       " [48, 343],\n",
       " [344, 48],\n",
       " [344, 48, 23],\n",
       " [343, 4],\n",
       " [708, 343, 84],\n",
       " [48, 709],\n",
       " [343, 10, 11, 344, 48, 23],\n",
       " [48, 10, 443, 344],\n",
       " [344, 710, 124, 48],\n",
       " [516],\n",
       " [234, 283],\n",
       " [711, 517],\n",
       " [712],\n",
       " [713],\n",
       " [714],\n",
       " [715],\n",
       " [716],\n",
       " [440, 516],\n",
       " [188, 518],\n",
       " [188, 518, 307],\n",
       " [717],\n",
       " [718],\n",
       " [719, 517],\n",
       " [720, 167],\n",
       " [519],\n",
       " [444],\n",
       " [444, 261],\n",
       " [444, 721, 722],\n",
       " [519, 308, 125],\n",
       " [4, 19, 21, 120, 10, 235, 2, 8, 7],\n",
       " [4, 19, 59, 2, 8, 7],\n",
       " [445, 4, 22, 10, 6, 2, 1],\n",
       " [59, 4, 10, 235, 2, 9, 1],\n",
       " [4, 22, 151, 21, 120, 2, 8, 7],\n",
       " [21, 120, 2, 1, 6, 4, 22],\n",
       " [4, 59, 10, 60, 2, 1],\n",
       " [54, 14, 59, 4, 22, 10, 6, 2, 8, 7],\n",
       " [4, 22, 151, 59, 2, 1],\n",
       " [59, 46, 22, 10, 16, 520, 2, 8, 7],\n",
       " [4, 19, 59, 2, 1],\n",
       " [59, 1, 4, 19],\n",
       " [59, 4, 10, 6, 2, 1],\n",
       " [445, 2, 1, 6, 4, 19],\n",
       " [6, 39, 59, 2, 1],\n",
       " [1, 29, 59, 4],\n",
       " [2, 1, 16, 345, 59, 4, 19],\n",
       " [20, 2, 1, 6, 59, 4],\n",
       " [59, 10, 60, 2, 1, 4],\n",
       " [39, 32, 20, 2, 8, 7],\n",
       " [39, 236, 20, 2, 8, 7],\n",
       " [39, 152, 2, 1],\n",
       " [39, 32, 346, 31, 2, 1],\n",
       " [39, 32, 83, 2, 8, 7],\n",
       " [39, 32, 120, 2, 9, 1],\n",
       " [5, 32, 20, 1, 387, 723, 21, 120],\n",
       " [2, 46, 66, 16, 168, 309, 189, 32, 20, 2, 1],\n",
       " [39, 32, 83, 2, 1, 58, 724],\n",
       " [5, 6, 446, 32, 447, 21, 120, 2, 8, 7],\n",
       " [2, 46, 66, 16, 126, 725, 32, 20, 2, 1],\n",
       " [32, 20, 2, 1, 39, 41],\n",
       " [152, 2, 1, 39, 23],\n",
       " [39, 23, 236, 20, 346, 31, 2, 1],\n",
       " [158, 20, 2, 1, 521, 12],\n",
       " [39, 32, 346, 31, 2, 1],\n",
       " [6, 347, 32, 20, 2, 1, 12],\n",
       " [1, 32, 726, 39, 41],\n",
       " [32, 20, 2, 1, 58, 69, 17],\n",
       " [388, 12, 32, 127, 59, 2, 1],\n",
       " [237, 16, 215, 32, 20, 2, 1],\n",
       " [32, 20, 1],\n",
       " [521, 202, 727],\n",
       " [348, 522, 728, 20, 2, 1],\n",
       " [5, 67, 2, 8, 7, 102, 389, 238, 159, 40],\n",
       " [5, 67, 2, 1, 389, 216, 262, 310, 238, 159, 40],\n",
       " [67, 2, 8, 69, 5, 102, 389, 238, 27, 159, 40],\n",
       " [5, 67, 2, 1, 448, 311, 27, 159, 40],\n",
       " [5, 159, 40, 449, 450, 67, 2, 1],\n",
       " [5, 67, 1, 102, 390, 450, 75, 159, 40],\n",
       " [263, 102, 1, 391, 67, 310, 311, 27, 40],\n",
       " [5, 1, 391, 67, 238, 27, 159, 40, 729],\n",
       " [67, 2, 1, 5, 389, 13, 75, 159, 40],\n",
       " [5, 8, 7, 262, 391, 67, 310, 311, 27, 40],\n",
       " [67, 2, 1, 102, 523, 12, 23, 203, 238, 40],\n",
       " [1, 102, 392, 67, 12, 11, 451, 730, 40],\n",
       " [67, 2, 9, 1, 284, 311, 36, 40, 452],\n",
       " [67, 2, 1, 523, 262, 12, 203, 238, 159, 40],\n",
       " [67, 1, 102, 731, 203, 732, 36, 40, 12],\n",
       " [5, 67, 2, 1, 284, 451, 159, 40],\n",
       " [1, 733, 392, 67, 11, 451, 239, 40, 12],\n",
       " [6, 450, 67, 2, 1, 734, 735, 36, 40],\n",
       " [263, 102, 1, 392, 67, 238, 40],\n",
       " [67, 1],\n",
       " [15, 121, 38, 3, 62, 2, 8, 7],\n",
       " [15, 92, 38, 3, 62, 2, 8, 7],\n",
       " [121, 38, 3, 62, 2, 1, 169, 4],\n",
       " [15, 78, 38, 2, 8, 7],\n",
       " [4, 22, 349, 38, 3, 62, 2, 1],\n",
       " [121, 38, 1, 13, 3, 62, 15],\n",
       " [15, 24, 217, 218, 3, 62, 2, 8, 7],\n",
       " [92, 38, 2, 9, 1, 15, 453],\n",
       " [4, 61, 38, 13, 3, 62, 2, 1],\n",
       " [15, 121, 219, 3, 62, 2, 8, 7],\n",
       " [38, 3, 62, 2, 1, 169, 4, 453],\n",
       " [17, 23, 24, 44, 2, 1],\n",
       " [121, 38, 3, 62, 2, 1, 17, 41],\n",
       " [70, 153, 44, 2, 1, 240, 17],\n",
       " [92, 44, 3, 62, 2, 1, 312, 17],\n",
       " [78, 44, 2, 1, 4, 19],\n",
       " [44, 285, 3, 2, 1, 736, 12, 23],\n",
       " [17, 24, 44, 20, 2, 1],\n",
       " [349, 38, 2, 1, 4, 19],\n",
       " [11, 44, 3, 62, 2, 1, 71, 393, 524],\n",
       " [219, 2, 1, 17, 453],\n",
       " [15, 24, 217, 2, 8, 7],\n",
       " [348, 44, 737, 17, 240],\n",
       " [17, 23, 738, 348, 44],\n",
       " [5, 8, 7, 43, 85, 49, 13, 204, 3, 62],\n",
       " [5, 1, 43, 85, 49, 13, 204, 3, 62],\n",
       " [8, 7, 5, 33, 85, 49, 13, 3, 62],\n",
       " [85, 49, 13, 204, 3, 62, 5, 60, 2, 1],\n",
       " [5, 6, 85, 204, 3, 62, 190, 49, 2, 1],\n",
       " [1, 5, 525, 85, 49, 13, 204, 3, 62],\n",
       " [5, 3, 62, 2, 1, 16, 160, 190, 85, 49],\n",
       " [5, 6, 204, 3, 62, 2, 1, 190, 85, 49],\n",
       " [8, 7, 5, 43, 204, 85, 49],\n",
       " [5, 1, 33, 21, 204, 3, 62, 27, 85, 49],\n",
       " [85, 49, 13, 204, 3, 62, 5, 60, 2, 8, 7],\n",
       " [1, 6, 85, 49, 12, 11, 110],\n",
       " [17, 23, 70, 153, 44, 220, 85, 49, 2, 1],\n",
       " [1, 313, 204, 3, 62, 739, 85, 49, 12],\n",
       " [6, 12, 85, 49, 11, 44, 2, 1],\n",
       " [16, 44, 2, 1, 220, 49, 12],\n",
       " [110, 1, 220, 85, 49, 526, 12],\n",
       " [1, 29, 21, 204, 220, 85, 49, 12],\n",
       " [70, 29, 49, 16, 12, 110, 1, 527, 63],\n",
       " [6, 34, 85, 49, 2, 1, 12],\n",
       " [17, 24, 44, 2, 1, 220, 85, 49],\n",
       " [4, 22, 93, 10, 394, 13, 38],\n",
       " [4, 22, 93, 10, 314, 13, 38],\n",
       " [93, 4, 22, 10, 394, 13, 217, 2, 1],\n",
       " [4, 22, 350, 10, 314, 13, 92, 38],\n",
       " [13, 38, 93, 4, 22, 10, 71, 740],\n",
       " [93, 4, 10, 394, 13, 219, 2, 8, 7],\n",
       " [4, 22, 264, 93, 13, 38, 2, 1],\n",
       " [350, 4, 22, 10, 71, 741, 13, 38, 2, 1],\n",
       " [13, 217, 2, 1, 93, 4, 22, 10, 314],\n",
       " [4, 22, 93, 10, 71, 742, 111, 38],\n",
       " [4, 743, 286, 13, 92, 38, 2, 8, 7],\n",
       " [93, 4, 19, 10, 71, 528, 11, 44, 2, 1],\n",
       " [11, 44, 2, 1, 170, 350, 4, 19],\n",
       " [4, 19, 10, 71, 744, 11, 38, 2, 1],\n",
       " [264, 93, 44, 2, 1, 4, 19],\n",
       " [1, 529, 350, 4, 11, 219],\n",
       " [70, 153, 44, 2, 1, 745, 4, 19],\n",
       " [4, 19, 82, 93, 11, 44, 3, 62, 2, 1],\n",
       " [350, 286, 4, 10, 395, 11, 44, 2, 1],\n",
       " [44, 2, 1, 71, 530, 93, 4],\n",
       " [93, 38, 2, 1, 6, 4, 19, 23],\n",
       " [93, 38, 1],\n",
       " [25, 265, 38, 50, 2, 8, 7],\n",
       " [25, 35, 38, 50, 2, 8, 7],\n",
       " [25, 38, 50, 454, 2, 8, 7],\n",
       " [25, 265, 351, 38, 50, 2, 1],\n",
       " [25, 287, 38, 50, 2, 8, 7],\n",
       " [25, 35, 38, 50, 9, 1],\n",
       " [25, 3, 71, 315, 38, 50, 2, 1],\n",
       " [25, 38, 50, 241, 2, 8, 7],\n",
       " [38, 50, 2, 1, 25, 221],\n",
       " [25, 265, 13, 315, 38, 50, 2, 1],\n",
       " [38, 50, 8, 7, 454, 25],\n",
       " [25, 23, 35, 44, 50, 2, 1],\n",
       " [44, 50, 2, 1, 89, 25],\n",
       " [38, 50, 2, 1, 25, 454],\n",
       " [25, 71, 44, 50, 2, 1],\n",
       " [35, 44, 50, 2, 1, 25, 41],\n",
       " [1, 313, 38, 50, 25],\n",
       " [44, 50, 2, 1, 89, 72, 242, 39],\n",
       " [25, 746, 44, 50, 2, 1],\n",
       " [287, 44, 50, 2, 1, 25, 19],\n",
       " [25, 3, 62, 243, 44, 50, 2, 1],\n",
       " [265, 38, 50],\n",
       " [15, 61, 38, 50, 2, 8, 7],\n",
       " [15, 24, 38, 50, 2, 8, 7],\n",
       " [4, 78, 38, 50, 2, 1],\n",
       " [15, 121, 38, 50, 2, 9, 1],\n",
       " [4, 22, 349, 38, 50, 2, 8, 7],\n",
       " [15, 92, 38, 50, 2, 1],\n",
       " [4, 61, 189, 13, 38, 50, 2, 8, 7],\n",
       " [15, 288, 219, 50, 2, 9, 1],\n",
       " [4, 22, 82, 14, 61, 38, 50, 2, 1],\n",
       " [15, 121, 219, 50, 2, 8, 7],\n",
       " [4, 22, 10, 71, 205, 13, 38, 50, 2, 1],\n",
       " [17, 23, 24, 44, 50, 2, 1],\n",
       " [78, 44, 50, 2, 1, 4, 19],\n",
       " [121, 44, 50, 2, 9, 1, 17, 41],\n",
       " [4, 19, 349, 11, 44, 50, 2, 1],\n",
       " [92, 44, 50, 2, 1, 17, 23],\n",
       " [4, 61, 189, 44, 50, 2, 1],\n",
       " [17, 24, 219, 50, 2, 1],\n",
       " [4, 19, 82, 11, 44, 50, 2, 1],\n",
       " [121, 219, 50, 2, 1, 312, 17],\n",
       " [11, 44, 50, 2, 1, 71, 393, 19],\n",
       " [44, 50],\n",
       " [4, 22, 289, 32, 10, 71, 455],\n",
       " [289, 32, 4, 22, 10, 170, 455],\n",
       " [4, 22, 32, 10, 71, 456, 124, 3],\n",
       " [32, 4, 22, 10, 457, 30, 76],\n",
       " [4, 22, 347, 32, 10, 71, 455],\n",
       " [289, 76, 4, 22, 10, 243, 747],\n",
       " [4, 22, 396, 32, 10, 531],\n",
       " [4, 22, 32, 10, 170, 456, 111, 20],\n",
       " [347, 32, 4, 22, 10, 170, 532],\n",
       " [4, 19, 10, 71, 66, 158],\n",
       " [289, 32, 20, 2, 1, 4, 19, 23],\n",
       " [4, 19, 347, 32, 10, 748, 456],\n",
       " [396, 32, 4, 19, 10, 531, 2, 1],\n",
       " [70, 20, 2, 1, 158, 4, 19],\n",
       " [6, 32, 4, 19, 10, 71, 532],\n",
       " [289, 76, 20, 2, 1, 4, 19, 41],\n",
       " [4, 19, 10, 457, 30, 32, 20, 2, 1],\n",
       " [347, 76, 20, 2, 1, 4, 19],\n",
       " [11, 20, 2, 1, 170, 158, 4, 19],\n",
       " [289, 32],\n",
       " [5, 8, 7, 222, 36, 27, 53, 26, 266, 55, 13, 43, 34],\n",
       " [5, 1, 33, 37, 36, 27, 53, 13, 43, 34],\n",
       " [5, 8, 7, 222, 36, 27, 266, 55, 30, 749, 34],\n",
       " [5, 9, 1, 352, 37, 36, 27, 53, 13, 21, 34],\n",
       " [5, 6, 353, 244, 1, 14, 266, 55, 13, 206, 34],\n",
       " [5, 8, 7, 33, 191, 53, 13, 34],\n",
       " [5, 1, 222, 36, 27, 397, 533, 13, 43, 34],\n",
       " [5, 6, 34, 10, 267, 190, 37, 36, 1, 27, 53],\n",
       " [5, 1, 206, 34, 87, 37, 36, 27, 750, 55],\n",
       " [5, 9, 1, 33, 21, 34, 190, 458, 27, 266],\n",
       " [5, 1, 352, 37, 36, 27, 53, 26, 397, 13, 43, 34],\n",
       " [1, 6, 37, 36, 36, 53, 11, 167, 34, 12],\n",
       " [9, 1, 29, 191, 53, 11, 34, 12, 23],\n",
       " [1, 37, 316, 266, 55, 11, 21, 34, 12],\n",
       " [6, 12, 34, 2, 1, 87, 37, 36, 36, 53],\n",
       " [1, 167, 34, 72, 353, 36, 397, 55, 12],\n",
       " [70, 153, 34, 2, 1, 6, 10, 72, 37, 36, 36, 53, 12],\n",
       " [1, 29, 21, 34, 316, 191, 53, 12],\n",
       " [34, 2, 1, 6, 10, 267, 220, 458, 12],\n",
       " [9, 1, 37, 36, 36, 397, 533, 11, 34, 12, 41],\n",
       " [34, 2, 1, 16, 751, 72, 37, 36, 36, 266, 12],\n",
       " [752, 34],\n",
       " [5, 32, 20, 16, 354, 112, 6, 355, 245],\n",
       " [5, 76, 20, 16, 354, 112, 390, 317, 245],\n",
       " [5, 1, 398, 356, 171, 76, 112, 6, 399, 357],\n",
       " [534, 32, 20, 2, 1, 354, 459, 355, 245],\n",
       " [5, 6, 223, 171, 76, 20, 2, 1],\n",
       " [5, 9, 1, 753, 171, 76, 112, 6, 317, 400],\n",
       " [5, 76, 20, 16, 535, 26, 354, 111, 390, 399, 357],\n",
       " [5, 8, 7, 43, 356, 171, 76, 20],\n",
       " [5, 6, 268, 401, 171, 76, 51, 3, 10, 317, 245],\n",
       " [15, 223, 1, 460, 171, 32, 20, 112, 6, 355, 245],\n",
       " [5, 3, 16, 269, 171, 32, 20, 2, 1],\n",
       " [15, 223, 1, 460, 171, 32, 20, 112, 6, 355, 245],\n",
       " [5, 6, 268, 401, 171, 76, 51, 3, 10, 317, 245],\n",
       " [5, 8, 7, 43, 356, 171, 76, 20],\n",
       " [70, 6, 399, 357, 16, 358, 158, 20, 2, 1, 12],\n",
       " [1, 536, 356, 11, 358, 76, 12, 23, 70, 307, 317, 245],\n",
       " [158, 20, 2, 1, 16, 535, 26, 354, 12, 70, 307, 526],\n",
       " [6, 12, 223, 358, 158, 2, 1, 70, 6, 355, 400],\n",
       " [9, 1, 754, 171, 76, 12, 70, 6, 399, 245],\n",
       " [70, 307, 12, 6, 236, 16, 359, 171, 76, 2, 1, 12],\n",
       " [17, 223, 1, 537, 171, 32, 20],\n",
       " [6, 268, 11, 358, 76, 2, 1, 12, 70, 307, 317],\n",
       " [3, 16, 359, 171, 158, 20, 2, 1, 12, 41],\n",
       " [1, 167, 28, 11, 755, 76, 12, 23],\n",
       " [358, 32],\n",
       " [5, 8, 7, 43, 34, 42, 13, 3, 140],\n",
       " [5, 1, 43, 34, 51, 3, 140],\n",
       " [5, 6, 34, 42, 2, 1, 13, 3, 27, 49, 56],\n",
       " [5, 3, 140, 16, 126, 34, 2, 8, 7],\n",
       " [5, 1, 206, 34, 51, 3, 140],\n",
       " [5, 6, 21, 34, 49, 2, 8, 7],\n",
       " [5, 1, 33, 34, 13, 192, 49, 3],\n",
       " [5, 8, 7, 398, 34, 360, 3, 140],\n",
       " [5, 6, 34, 2, 1, 13, 3, 27, 49, 56, 26, 246],\n",
       " [5, 3, 140, 126, 34, 42, 2, 1],\n",
       " [5, 1, 206, 34, 49, 51, 154],\n",
       " [1, 6, 34, 11, 3, 140, 12],\n",
       " [9, 1, 167, 34, 12, 11, 10, 140],\n",
       " [3, 140, 16, 141, 34, 2, 1, 12],\n",
       " [1, 29, 21, 34, 49, 12],\n",
       " [6, 12, 34, 42, 11, 3, 140, 2, 1],\n",
       " [34, 1, 60, 11, 49, 56, 26, 246, 12],\n",
       " [70, 29, 49, 16, 141, 34, 2, 1, 12],\n",
       " [6, 192, 49, 3, 30, 361, 34, 2, 1],\n",
       " [3, 140, 141, 34, 2, 1, 12, 23],\n",
       " [1, 318, 34, 11, 154, 10, 140, 12],\n",
       " [34, 49],\n",
       " [5, 32, 20, 319, 290, 113, 58],\n",
       " [5, 32, 20, 2, 1, 290, 113, 58],\n",
       " [5, 6, 239, 32, 20, 113, 538, 2, 8, 7],\n",
       " [5, 32, 20, 2, 1, 16, 390, 756, 113, 58],\n",
       " [5, 9, 1, 461, 32, 20, 127, 58],\n",
       " [5, 32, 83, 2, 8, 7, 290, 113, 58],\n",
       " [5, 6, 539, 239, 32, 20, 113, 58, 2, 1],\n",
       " [5, 540, 20, 2, 1, 16, 387, 113, 538],\n",
       " [5, 32, 20, 2, 1, 448, 36, 26, 290, 127, 58],\n",
       " [5, 1, 757, 32, 20, 387, 113, 58, 541],\n",
       " [5, 9, 1, 391, 32, 20, 113, 58],\n",
       " [32, 20, 2, 1, 127, 58, 290, 12, 23],\n",
       " [9, 1, 758, 32, 20, 127, 58, 12],\n",
       " [32, 20, 2, 1, 36, 759, 26, 290, 127, 58],\n",
       " [6, 239, 32, 20, 12, 127, 58, 2, 1],\n",
       " [540, 20, 2, 1, 16, 388, 127, 58, 12],\n",
       " [1, 102, 392, 32, 20, 127, 58, 12, 23],\n",
       " [32, 83, 2, 1, 16, 542, 127, 58, 12, 41],\n",
       " [1, 448, 760, 32, 20, 127, 58, 12],\n",
       " [127, 58, 541, 62, 32, 20, 1, 290, 12],\n",
       " [6, 539, 32, 20, 2, 1, 542, 127, 58, 12],\n",
       " [239, 32],\n",
       " [15, 224, 8, 7, 27, 86, 40],\n",
       " [169, 4, 224, 1, 27, 86, 40],\n",
       " [15, 761, 8, 7, 27, 402, 40],\n",
       " [5, 1, 33, 37, 36, 27, 543, 40],\n",
       " [15, 353, 8, 7, 27, 86, 40],\n",
       " [762, 46, 1, 352, 224, 27, 402, 40],\n",
       " [5, 8, 7, 462, 27, 40, 13, 122, 83],\n",
       " [15, 155, 1, 30, 352, 224, 27, 86, 40],\n",
       " [5, 9, 1, 33, 225, 27, 53, 40],\n",
       " [15, 8, 7, 222, 36, 27, 40, 30, 83, 14, 142],\n",
       " [263, 544, 224, 1, 27, 40, 30, 122, 291],\n",
       " [17, 23, 224, 1, 36, 86, 40],\n",
       " [1, 29, 37, 36, 36, 53, 40, 12],\n",
       " [263, 544, 23, 224, 1, 27, 402, 40],\n",
       " [9, 1, 462, 36, 40, 12, 11, 320, 83],\n",
       " [6, 353, 1, 36, 543, 40, 12],\n",
       " [17, 545, 1, 2, 86, 40],\n",
       " [1, 102, 37, 36, 36, 53, 40, 12],\n",
       " [225, 1, 36, 40, 17, 41],\n",
       " [1, 29, 224, 546, 12, 36, 402, 40, 11, 291],\n",
       " [17, 353, 1, 36, 40, 30, 83, 14, 142],\n",
       " [5, 6, 21, 73, 26, 37, 36, 27, 53],\n",
       " [5, 8, 7, 33, 37, 36, 27, 53, 13, 73],\n",
       " [5, 3, 1, 16, 75, 21, 73, 2, 53, 191],\n",
       " [5, 9, 1, 206, 21, 73, 190, 37, 36, 27, 53],\n",
       " [5, 6, 547, 73, 51, 3, 1, 2, 53, 226],\n",
       " [5, 8, 7, 222, 36, 27, 53, 13, 21, 73],\n",
       " [5, 3, 1, 763, 75, 73, 190, 37, 36, 27, 53],\n",
       " [5, 6, 21, 73, 10, 267, 124, 1, 190, 191, 40],\n",
       " [5, 1, 33, 21, 37, 36, 27, 53, 13, 548, 73],\n",
       " [5, 9, 1, 262, 206, 73, 51, 154, 2, 53, 191],\n",
       " [1, 6, 21, 73, 11, 3, 12],\n",
       " [3, 1, 16, 47, 73, 2, 53, 191, 12],\n",
       " [9, 1, 29, 37, 36, 36, 53, 11, 73, 12],\n",
       " [1, 102, 318, 21, 73, 2, 53, 12, 23],\n",
       " [6, 547, 73, 2, 53, 11, 3, 1, 12],\n",
       " [3, 1, 243, 47, 73, 12],\n",
       " [21, 73, 2, 1, 549, 220, 191, 40, 12],\n",
       " [1, 29, 37, 36, 11, 548, 73, 12, 41],\n",
       " [6, 12, 21, 73, 262, 2, 1, 220, 53, 191],\n",
       " [17, 24, 3, 1, 141, 73, 2, 53, 191],\n",
       " [21, 73],\n",
       " [15, 8, 7, 122, 3, 30, 362, 321, 247, 86, 37],\n",
       " [4, 22, 21, 10, 267, 1, 13, 125, 3, 207, 37],\n",
       " [15, 1, 125, 3, 362, 321, 247, 86, 403],\n",
       " [4, 78, 8, 7, 30, 550, 3, 13, 86, 37],\n",
       " [5, 6, 142, 322, 51, 3, 1],\n",
       " [15, 9, 1, 292, 3, 310, 207, 463, 86, 37],\n",
       " [4, 22, 293, 10, 764, 1, 13, 3, 30, 463, 86, 37],\n",
       " [5, 1, 43, 21, 323, 322, 51, 154],\n",
       " [15, 8, 7, 125, 3, 247, 464, 86, 37],\n",
       " [4, 22, 79, 26, 28, 1, 13, 551, 765, 3, 2, 86, 403],\n",
       " [15, 1, 550, 3, 27, 103, 10, 311, 13, 86, 37],\n",
       " [1, 29, 21, 4, 19, 11, 193, 3, 207, 37],\n",
       " [17, 23, 24, 1, 766, 154, 203, 207, 110, 86, 37],\n",
       " [1, 167, 142, 322, 11, 3, 12],\n",
       " [9, 1, 193, 3, 323, 37, 27, 24, 4, 19],\n",
       " [6, 21, 42, 72, 1, 203, 3, 207, 110, 86, 403, 12],\n",
       " [79, 4, 19, 10, 549, 1, 11, 3, 203, 207, 37],\n",
       " [1, 29, 28, 4, 11, 193, 3, 552, 86, 37],\n",
       " [3, 1, 141, 293, 4, 19, 11, 767, 37],\n",
       " [1, 6, 21, 323, 322, 11, 3, 12],\n",
       " [17, 24, 1, 768, 103, 10, 311, 11, 86, 37],\n",
       " [247, 86, 37],\n",
       " [5, 6, 21, 363, 194, 51, 3],\n",
       " [5, 1, 33, 21, 13, 364, 553, 194, 3],\n",
       " [5, 8, 7, 43, 21, 194, 51, 154],\n",
       " [5, 6, 21, 42, 2, 1, 13, 3, 10, 554, 324, 194],\n",
       " [5, 9, 1, 122, 3, 30, 769, 365, 404],\n",
       " [5, 1, 43, 142, 194, 13, 3],\n",
       " [5, 6, 64, 194, 10, 16, 366, 3, 2, 1],\n",
       " [5, 8, 7, 33, 555, 465, 13, 3],\n",
       " [15, 1, 125, 3, 30, 364, 103, 770],\n",
       " [5, 3, 2, 1, 16, 75, 21, 556, 26, 194],\n",
       " [5, 9, 1, 206, 21, 557, 365, 51, 3],\n",
       " [1, 29, 21, 11, 558, 553, 559, 3, 12],\n",
       " [6, 12, 21, 194, 2, 1, 11, 3],\n",
       " [70, 554, 465, 6, 21, 42, 2, 1, 12],\n",
       " [9, 1, 320, 3, 11, 89, 365, 404, 12],\n",
       " [1, 167, 142, 194, 11, 3, 12],\n",
       " [6, 64, 194, 4, 19, 2, 1, 10, 16, 560],\n",
       " [1, 29, 555, 465, 11, 3, 12],\n",
       " [17, 1, 193, 3, 558, 103, 559],\n",
       " [3, 1, 16, 47, 21, 556, 26, 194, 12],\n",
       " [9, 1, 318, 21, 557, 365, 11, 3, 12],\n",
       " [21, 194],\n",
       " [5, 8, 7, 43, 142, 103, 172, 51, 3],\n",
       " [5, 1, 206, 142, 103, 172, 13, 3],\n",
       " [5, 6, 21, 142, 103, 2, 8, 7],\n",
       " [5, 3, 1, 16, 75, 142, 103, 172],\n",
       " [5, 9, 1, 43, 466, 103, 51, 154],\n",
       " [5, 6, 142, 561, 325, 14, 562, 325, 2, 1],\n",
       " [5, 3, 2, 1, 126, 104, 143, 142, 103, 172],\n",
       " [5, 9, 1, 33, 21, 363, 103, 246],\n",
       " [5, 1, 43, 94, 26, 467, 103, 51, 3],\n",
       " [5, 3, 16, 75, 21, 142, 103, 2, 208, 67, 2, 1],\n",
       " [5, 6, 21, 103, 172, 13, 551, 322, 3, 2, 1],\n",
       " [1, 6, 142, 103, 172, 11, 3, 12],\n",
       " [3, 1, 16, 47, 466, 103, 172, 12],\n",
       " [9, 1, 318, 467, 103, 12, 23],\n",
       " [6, 12, 21, 142, 561, 325, 14, 562, 325, 2, 1],\n",
       " [3, 1, 141, 104, 143, 142, 103, 172, 12],\n",
       " [1, 29, 94, 103, 246, 11, 3, 12],\n",
       " [6, 142, 103, 2, 208, 67, 2, 1, 12],\n",
       " [17, 24, 47, 21, 103, 172, 2, 1],\n",
       " [1, 6, 467, 26, 466, 11, 771, 325, 3, 12],\n",
       " [6, 21, 325, 172, 11, 323, 322, 2, 1, 12],\n",
       " [15, 24, 405, 772, 363, 83, 209, 26, 236, 20, 773, 152, 2, 1],\n",
       " [15, 61, 76, 209, 26, 152, 2, 1],\n",
       " [15, 24, 315, 76, 236, 20, 2, 8, 7],\n",
       " [4, 22, 563, 76, 209, 26, 152, 2, 1],\n",
       " [15, 78, 13, 405, 152, 2, 1],\n",
       " [237, 3, 16, 405, 209, 26, 152, 2, 8, 7],\n",
       " [5, 76, 152, 2, 1, 16, 205, 216, 144],\n",
       " [4, 22, 564, 76, 10, 60, 13, 209, 2, 1],\n",
       " [15, 24, 405, 236, 20, 112, 205, 72, 208, 9, 1],\n",
       " [5, 1, 565, 76, 152, 190, 566, 567],\n",
       " [15, 121, 76, 209, 26, 152, 51, 3, 62, 2, 1],\n",
       " [17, 23, 24, 158, 152, 2, 1],\n",
       " [61, 76, 209, 2, 1, 17, 41],\n",
       " [16, 12, 158, 236, 20, 2, 1, 220, 144],\n",
       " [78, 11, 158, 152, 2, 1, 17],\n",
       " [2, 46, 19, 16, 158, 209, 1],\n",
       " [4, 19, 563, 76, 152, 2, 1],\n",
       " [16, 566, 567, 11, 158, 152, 2, 1, 12],\n",
       " [70, 153, 158, 20, 152, 2, 1, 17],\n",
       " [564, 76, 11, 209, 2, 1, 6, 4, 19],\n",
       " [158, 152, 1],\n",
       " [121, 76, 209, 51, 3, 62, 2, 1, 17],\n",
       " [5, 8, 7, 1, 33, 21, 270, 14, 248],\n",
       " [5, 1, 43, 21, 270, 14, 248],\n",
       " [5, 6, 21, 406, 14, 367, 2, 8, 7],\n",
       " [5, 9, 1, 33, 407, 83, 270, 14, 248],\n",
       " [5, 1, 206, 21, 368, 14, 326],\n",
       " [5, 6, 21, 120, 270, 2, 1],\n",
       " [5, 8, 7, 525, 21, 248],\n",
       " [5, 6, 151, 21, 406, 14, 367, 2, 1],\n",
       " [5, 3, 16, 774, 143, 407, 368, 26, 326, 2, 1],\n",
       " [5, 1, 33, 21, 83, 468, 469, 271, 248],\n",
       " [5, 1, 43, 28, 14, 21, 13, 407, 270, 14, 248],\n",
       " [1, 6, 21, 368, 14, 326, 12, 23],\n",
       " [9, 1, 29, 21, 406, 14, 367, 12],\n",
       " [16, 568, 20, 368, 26, 326, 2, 1, 12],\n",
       " [1, 313, 21, 270, 14, 248, 12],\n",
       " [6, 151, 21, 270, 2, 1, 12],\n",
       " [70, 153, 345, 326, 1, 6, 775, 12],\n",
       " [1, 318, 83, 188, 407, 248, 12],\n",
       " [4, 1, 29, 28, 11, 20, 368, 14, 326],\n",
       " [16, 568, 20, 468, 2, 1, 188, 367, 12, 41],\n",
       " [6, 12, 21, 120, 468, 406, 14, 367, 2, 1],\n",
       " [21, 270, 14, 248],\n",
       " [4, 84, 7, 95, 96],\n",
       " [4, 10, 569, 27, 7, 95, 96],\n",
       " [16, 570, 4, 84, 7, 95, 96],\n",
       " [4, 408, 72, 7, 95, 96],\n",
       " [4, 21, 10, 235, 2, 7, 95, 96],\n",
       " [4, 155, 7, 95, 96, 2, 8, 7],\n",
       " [4, 22, 64, 2, 7, 95, 96],\n",
       " [4, 272, 83, 2, 7, 95, 96],\n",
       " [7, 95, 96, 84, 21, 4],\n",
       " [15, 195, 83, 2, 7, 95, 96],\n",
       " [5, 7, 95, 96, 470, 13, 273, 3, 1],\n",
       " [4, 23, 7, 95, 96, 84],\n",
       " [16, 571, 12, 4, 84, 7, 95, 96],\n",
       " [7, 95, 96, 84, 11, 4],\n",
       " [21, 4, 19, 10, 6, 2, 7, 95, 96],\n",
       " [4, 408, 72, 7, 95, 96, 2, 1],\n",
       " [64, 4, 19, 10, 572, 2, 7, 95, 96],\n",
       " [272, 83, 2, 7, 95, 96, 4, 41],\n",
       " [7, 95, 96, 84, 21, 312, 17],\n",
       " [17, 195, 161, 2, 7, 95, 96],\n",
       " [7, 95, 96, 16, 366, 273, 3, 1, 12],\n",
       " [7, 95, 96],\n",
       " [4, 84, 123, 7],\n",
       " [4, 10, 569, 27, 123, 7],\n",
       " [16, 570, 4, 84, 123, 7],\n",
       " [4, 22, 21, 120, 10, 235, 2, 123, 7],\n",
       " [4, 272, 83, 2, 123, 7],\n",
       " [123, 7, 84, 573, 4],\n",
       " [5, 123, 7, 369, 72, 8, 7],\n",
       " [15, 195, 776, 2, 123, 7],\n",
       " [4, 23, 123, 7, 84],\n",
       " [16, 571, 12, 123, 7, 84, 4],\n",
       " [123, 7, 29, 21, 120, 4, 19],\n",
       " [272, 83, 2, 123, 7, 4, 41],\n",
       " [123, 7, 84, 573, 4, 23],\n",
       " [123, 7, 457, 369, 72, 1, 12],\n",
       " [17, 195, 161, 2, 123, 7],\n",
       " [4, 574, 123, 7, 36, 8, 7],\n",
       " [123, 7, 272, 2, 179, 4, 19],\n",
       " [4, 19, 64, 161, 2, 123, 7],\n",
       " [123, 7],\n",
       " [54, 4, 22, 10, 235, 124, 8, 7],\n",
       " [4, 22, 54, 10, 60, 2, 8, 7],\n",
       " [54, 4, 22, 10, 6, 2, 9, 1],\n",
       " [4, 22, 151, 54, 2, 8, 7],\n",
       " [39, 274, 54, 2, 1, 14, 4, 22],\n",
       " [4, 22, 179, 120, 10, 60, 2, 777, 1],\n",
       " [5, 1, 33, 54, 2, 179, 575, 14, 400],\n",
       " [54, 4, 22, 10, 16, 576, 3, 2, 8, 7],\n",
       " [4, 22, 21, 120, 10, 60, 2, 113, 54, 1],\n",
       " [54, 46, 22, 2, 1, 10, 565, 3, 62],\n",
       " [15, 577, 54, 2, 8, 7],\n",
       " [54, 4, 19, 10, 6, 2, 1],\n",
       " [1, 29, 39, 54, 23],\n",
       " [151, 54, 2, 1, 4, 19, 41],\n",
       " [6, 54, 575, 14, 400, 2, 1, 12],\n",
       " [54, 4, 19, 10, 16, 576, 2, 1],\n",
       " [179, 120, 2, 127, 54, 1, 4, 19],\n",
       " [54, 46, 19, 2, 1, 10, 313, 38, 3, 62],\n",
       " [17, 23, 577, 54, 2, 1],\n",
       " [2, 1, 6, 54, 4, 19, 10, 16, 520],\n",
       " [54, 1],\n",
       " [15, 112, 66, 160, 2, 778, 779, 275, 196, 26, 8, 55],\n",
       " [4, 10, 71, 66, 780, 112, 160, 2, 196, 26, 8, 55],\n",
       " [15, 61, 112, 66, 781, 20, 2, 196, 227, 160, 2, 1],\n",
       " [5, 6, 223, 1, 112, 66, 160, 2, 8, 55],\n",
       " [15, 173, 578, 321, 112, 66, 160, 2, 196, 26, 9, 55],\n",
       " [5, 236, 38, 16, 782, 112, 66, 409, 196],\n",
       " [15, 24, 471, 38, 2, 1, 112, 66, 160, 2, 8, 55],\n",
       " [4, 288, 783, 112, 66, 472, 88, 143, 196, 227, 160, 2, 1],\n",
       " [5, 66, 16, 471, 20, 2, 1, 112, 160, 2, 9, 55],\n",
       " [15, 223, 473, 32, 112, 66, 409, 8, 55],\n",
       " [5, 6, 579, 112, 66, 471, 38, 2, 1, 13, 20, 2, 196],\n",
       " [70, 66, 160, 2, 196, 17, 41, 784, 11, 474, 2, 1],\n",
       " [16, 12, 236, 38, 2, 1, 785, 70, 66, 475, 196],\n",
       " [17, 24, 786, 578, 321, 72, 1, 70, 160, 2, 9, 55],\n",
       " [1, 6, 223, 4, 70, 66, 153, 787, 20, 459, 160, 2, 196],\n",
       " [16, 12, 66, 474, 20, 2, 1, 70, 110, 9, 55],\n",
       " [4, 78, 11, 788, 2, 1, 70, 66, 160, 2, 8, 55],\n",
       " [1, 167, 579, 12, 70, 66, 474, 20, 459, 789, 196],\n",
       " [17, 473, 32, 20, 70, 66, 88, 143, 196],\n",
       " [473, 32, 209],\n",
       " [34],\n",
       " [4, 19, 34, 1],\n",
       " [34, 4, 22, 10, 235, 124, 8, 7],\n",
       " [4, 22, 396, 34, 10, 60, 2, 8, 7],\n",
       " [34, 4, 22, 10, 16, 366, 3, 2, 1],\n",
       " [4, 22, 21, 34, 10, 235, 124, 1],\n",
       " [5, 1, 43, 34, 56, 14, 246],\n",
       " [4, 22, 151, 34, 2, 8, 7],\n",
       " [5, 6, 34, 13, 3, 62, 2, 1],\n",
       " [396, 34, 4, 22, 10, 235, 360, 3, 1],\n",
       " [34, 4, 19, 10, 6, 2, 1],\n",
       " [1, 29, 21, 34, 4, 19, 11, 3],\n",
       " [6, 151, 34, 4, 19, 2, 1],\n",
       " [16, 141, 34, 56, 26, 246, 2, 1, 12],\n",
       " [790, 34, 2, 1, 6, 4, 19, 41],\n",
       " [3, 62, 2, 1, 16, 141, 34, 12],\n",
       " [1, 318, 34, 49, 14, 268, 357, 12],\n",
       " [70, 140, 16, 141, 34, 4, 2, 1],\n",
       " [21, 34, 2, 1, 6, 4, 19, 10, 16, 560],\n",
       " [34, 2, 1, 791, 11, 49, 26, 6, 268, 357, 792],\n",
       " [34, 1],\n",
       " [5, 1, 43, 21, 34],\n",
       " [15, 24, 75, 97, 13, 54, 145, 14, 146, 2, 1],\n",
       " [4, 61, 75, 97, 13, 54, 145, 14, 146, 2, 1],\n",
       " [15, 121, 38, 97, 13, 110, 54, 145, 14, 146, 1],\n",
       " [4, 22, 82, 75, 97, 13, 54, 145, 14, 146, 2, 1],\n",
       " [15, 78, 75, 97, 2, 1, 13, 276, 3, 145, 14, 146],\n",
       " [2, 46, 294, 14, 265, 351, 97, 13, 54, 145, 14, 146, 1],\n",
       " [5, 6, 32, 172, 13, 75, 97, 54, 145, 14, 146, 2, 1],\n",
       " [4, 22, 93, 10, 314, 13, 75, 97, 2, 1],\n",
       " [15, 24, 219, 97, 51, 276, 3, 54, 145, 14, 146, 1],\n",
       " [5, 97, 13, 145, 14, 146, 2, 1, 243, 51, 273, 276, 3],\n",
       " [5, 6, 580, 42, 13, 75, 97, 54, 145, 14, 146, 2, 1],\n",
       " [17, 23, 24, 47, 97, 11, 110, 145, 26, 146, 2, 1],\n",
       " [4, 19, 82, 47, 97, 2, 1, 11, 145, 14, 146],\n",
       " [121, 38, 97, 11, 145, 14, 146, 2, 1, 17, 41],\n",
       " [25, 14, 2, 46, 351, 97, 11, 145, 14, 146, 2, 1],\n",
       " [6, 32, 172, 12, 11, 47, 97, 2, 1],\n",
       " [93, 4, 19, 10, 170, 528, 11, 97, 2, 1],\n",
       " [17, 219, 97, 13, 276, 3, 145, 14, 146, 2, 1],\n",
       " [97, 11, 145, 14, 146, 2, 1, 243, 11, 273, 276, 3, 12],\n",
       " [1, 167, 580, 42, 12, 11, 47, 97, 145, 14, 146],\n",
       " [78, 47, 97, 2, 1, 11, 276, 3, 17, 23],\n",
       " [97, 1],\n",
       " [15, 24, 126, 63, 114, 65],\n",
       " [2, 46, 66, 16, 75, 63, 114, 65],\n",
       " [4, 61, 13, 315, 63, 114, 65],\n",
       " [15, 78, 126, 63, 114, 65, 2, 1],\n",
       " [5, 63, 114, 65, 16, 205, 2, 9, 1],\n",
       " [5, 6, 35, 42, 13, 63, 114, 65, 2, 1],\n",
       " [5, 63, 114, 65, 793, 38, 794, 795],\n",
       " [15, 24, 217, 13, 63, 114, 65, 2, 1],\n",
       " [5, 63, 114, 65, 60, 2, 228, 9, 26, 191, 128, 1],\n",
       " [17, 24, 47, 63, 114, 65, 2, 1],\n",
       " [63, 114, 65, 16, 796, 2, 9, 1, 12],\n",
       " [6, 35, 42, 12, 11, 63, 114, 65, 2, 1],\n",
       " [70, 153, 63, 114, 65, 71, 44, 524, 12, 41],\n",
       " [237, 66, 16, 47, 63, 114, 65],\n",
       " [78, 11, 63, 114, 65, 2, 1, 17],\n",
       " [63, 114, 65, 2, 1, 16, 44, 144, 12],\n",
       " [6, 12, 28, 63, 114, 65, 2, 228, 9, 1],\n",
       " [63, 114, 65, 2, 1, 6, 37, 36, 36, 191, 128, 12],\n",
       " [4, 19, 61, 11, 63, 114, 65, 2, 1],\n",
       " [63, 114, 65],\n",
       " [15, 24, 126, 87, 63, 197, 115, 116, 2, 1],\n",
       " [15, 24, 295, 87, 63, 197, 115, 116, 2, 1],\n",
       " [2, 46, 66, 16, 168, 87, 63, 197, 115, 116, 2, 1],\n",
       " [4, 61, 13, 126, 87, 63, 197, 115, 116, 2, 1],\n",
       " [15, 78, 13, 797, 87, 63, 197, 115, 116],\n",
       " [5, 87, 63, 197, 115, 116, 16, 210, 216, 144],\n",
       " [25, 14, 2, 46, 87, 63, 197, 115, 116, 581],\n",
       " [15, 24, 410, 87, 197, 115, 116, 112, 581, 216, 582],\n",
       " [5, 6, 583, 42, 13, 87, 63, 115, 116, 2, 1],\n",
       " [4, 22, 10, 71, 798, 13, 410, 87, 63, 197, 115, 116],\n",
       " [15, 24, 584, 35, 476, 87, 115, 116, 2, 1],\n",
       " [17, 24, 174, 87, 63, 115, 116, 2, 1],\n",
       " [2, 46, 16, 477, 87, 197, 115, 116, 1],\n",
       " [87, 63, 115, 116, 2, 1, 16, 411, 144, 12],\n",
       " [25, 14, 2, 46, 476, 87, 115, 116, 1, 799],\n",
       " [6, 583, 42, 12, 11, 87, 63, 115, 116],\n",
       " [4, 19, 78, 11, 174, 87, 115, 116, 2, 1],\n",
       " [70, 87, 800, 582, 17, 24, 801],\n",
       " [11, 345, 87, 115, 116, 71, 530, 4, 19],\n",
       " [24, 141, 35, 476, 87, 115, 116, 2, 1, 17],\n",
       " [4, 61, 11, 477, 87, 63, 197, 115, 116, 2, 1],\n",
       " [87, 63, 197],\n",
       " [534, 66, 217, 190, 129, 14, 130, 370, 4, 446, 244, 585, 21, 802],\n",
       " [5, 66, 16, 75, 38, 129, 14, 130, 216, 803],\n",
       " [4, 22, 446, 244, 85, 129, 14, 130, 2, 1],\n",
       " [5, 804, 13, 217, 2, 129, 14, 130, 370],\n",
       " [4, 586, 805, 72, 21, 129, 14, 130],\n",
       " [15, 61, 112, 66, 472, 217, 190, 129, 14, 130],\n",
       " [5, 6, 264, 42, 13, 75, 585, 85, 129, 14, 130],\n",
       " [5, 66, 71, 409, 244, 129, 26, 130, 26, 16, 806],\n",
       " [5, 32, 38, 387, 13, 129, 14, 130, 2, 1],\n",
       " [16, 12, 44, 129, 14, 130, 807, 2, 1],\n",
       " [4, 574, 85, 129, 36, 130, 2, 1],\n",
       " [70, 153, 44, 2, 129, 14, 130, 370, 16, 12],\n",
       " [4, 19, 586, 72, 85, 129, 14, 130, 2, 1],\n",
       " [17, 61, 11, 44, 2, 129, 14, 130, 316],\n",
       " [6, 264, 42, 12, 11, 47, 129, 14, 130, 370],\n",
       " [71, 475, 808, 587, 26, 16, 47, 129, 14, 130, 588],\n",
       " [32, 38, 129, 36, 130, 2, 1, 388, 12],\n",
       " [1, 536, 356, 44, 478, 85, 370, 12],\n",
       " [479, 371, 44, 2, 129, 26, 130, 26, 16, 588],\n",
       " [85, 38],\n",
       " [4, 117, 14, 147, 8, 7],\n",
       " [15, 117, 14, 147, 8, 7],\n",
       " [4, 22, 408, 198, 30, 117, 14, 147, 1],\n",
       " [4, 117, 8, 7, 30, 589, 412],\n",
       " [4, 147, 10, 809, 124, 8, 7],\n",
       " [15, 1, 590, 117, 14, 480],\n",
       " [4, 272, 198, 30, 147, 83, 1],\n",
       " [4, 22, 591, 10, 810, 30, 117, 14, 147, 1],\n",
       " [15, 117, 14, 147, 1, 122, 363, 3],\n",
       " [4, 155, 117, 14, 147, 30, 811, 592, 223, 1],\n",
       " [2, 46, 66, 16, 413, 309, 162, 414, 117, 14, 147, 1],\n",
       " [4, 23, 117, 14, 147, 1, 84],\n",
       " [17, 117, 14, 147, 1, 11, 812, 813],\n",
       " [4, 19, 408, 198, 72, 117, 14, 147, 1],\n",
       " [117, 589, 412, 1, 312, 17],\n",
       " [147, 1, 84, 814, 2, 179, 4, 19],\n",
       " [17, 1, 590, 117, 14, 480],\n",
       " [4, 591, 10, 593, 1, 30, 117, 14, 480],\n",
       " [117, 14, 147, 1, 122, 363, 3, 17, 41],\n",
       " [155, 117, 14, 147, 30, 592, 223, 1, 4, 19],\n",
       " [2, 46, 16, 477, 372, 162, 414, 117, 14, 147, 1],\n",
       " [117, 147, 1],\n",
       " [249, 25, 8, 7, 277],\n",
       " [25, 8, 7, 296],\n",
       " [324, 58, 39, 1, 89, 277],\n",
       " [39, 327, 8, 7, 594, 277],\n",
       " [25, 9, 1, 162, 415],\n",
       " [249, 58, 39, 8, 7, 415],\n",
       " [308, 39, 58, 1, 277, 469, 148],\n",
       " [4, 328, 250, 8, 7],\n",
       " [324, 287, 4, 8, 7, 296],\n",
       " [25, 242, 162, 481, 8, 7],\n",
       " [39, 595, 8, 7, 111, 69],\n",
       " [1, 277, 249, 25, 23],\n",
       " [58, 39, 1, 89, 6],\n",
       " [284, 39, 327, 1, 277],\n",
       " [25, 9, 1, 89, 415, 162],\n",
       " [249, 58, 39, 1, 482],\n",
       " [39, 595, 1, 188, 148],\n",
       " [25, 242, 162, 481, 1],\n",
       " [284, 39, 58, 1, 415],\n",
       " [58, 250, 1],\n",
       " [48, 10, 596, 1],\n",
       " [48, 597, 1],\n",
       " [1, 296, 124, 48],\n",
       " [4, 22, 192, 26, 211, 10, 416, 8, 7],\n",
       " [4, 192, 10, 175, 329, 8, 7],\n",
       " [211, 4, 22, 10, 416, 124, 1],\n",
       " [5, 1, 33, 211, 417, 26, 598],\n",
       " [4, 22, 483, 26, 211, 162, 10, 815, 1],\n",
       " [192, 4, 10, 175, 160, 124, 8, 7],\n",
       " [15, 599, 211, 54, 14, 21, 120, 2, 1],\n",
       " [4, 192, 118, 14, 77, 10, 329, 124, 1],\n",
       " [5, 8, 7, 33, 211, 600],\n",
       " [5, 1, 33, 192, 460, 212, 83],\n",
       " [4, 22, 484, 10, 175, 329, 124, 1],\n",
       " [192, 4, 19, 10, 175, 329, 1],\n",
       " [1, 284, 141, 211, 4, 19],\n",
       " [9, 1, 29, 211, 417, 26, 598, 12, 23],\n",
       " [6, 483, 162, 4, 19, 10, 416, 1],\n",
       " [192, 118, 14, 77, 4, 19, 10, 175, 160, 1],\n",
       " [17, 599, 211, 54, 14, 445, 2, 1],\n",
       " [1, 29, 211, 600, 12],\n",
       " [6, 192, 212, 83, 10, 329, 1, 12],\n",
       " [4, 19, 484, 251, 10, 175, 816, 1],\n",
       " [211, 14, 483, 297, 1, 4, 19, 41],\n",
       " [192, 1],\n",
       " [15, 298, 8, 7, 2, 271, 118, 14, 77],\n",
       " [169, 4, 298, 8, 7, 2, 330, 14, 86],\n",
       " [15, 601, 1, 2, 817, 118, 14, 77],\n",
       " [5, 8, 7, 485, 2, 271, 602],\n",
       " [15, 603, 1, 2, 244, 8, 55, 2, 330],\n",
       " [5, 1, 110, 30, 44, 8, 486, 2, 330, 14, 86],\n",
       " [15, 1, 604, 124, 266, 83, 77],\n",
       " [4, 22, 49, 1, 10, 122, 818, 2, 271, 77],\n",
       " [15, 819, 1, 27, 8, 55, 2, 605],\n",
       " [5, 3, 1, 102, 75, 80, 77],\n",
       " [15, 820, 119, 14, 3, 414, 298, 1],\n",
       " [17, 298, 1, 2, 330, 14, 77],\n",
       " [1, 110, 601, 8, 486, 12, 23],\n",
       " [5, 1, 485, 2, 208, 275],\n",
       " [17, 23, 603, 1, 2, 244, 821, 55, 2, 330],\n",
       " [1, 604, 2, 271, 602, 12, 41],\n",
       " [49, 4, 19, 10, 606, 1, 485, 77],\n",
       " [3, 1, 102, 47, 80, 77, 12],\n",
       " [17, 822, 1, 331, 8, 55, 2, 605],\n",
       " [4, 823, 119, 14, 3, 537, 298, 1],\n",
       " [1, 175, 141, 824, 72, 266, 77, 12],\n",
       " [237, 252, 8, 7],\n",
       " [4, 252, 189, 8, 7],\n",
       " [2, 46, 294, 9, 1, 607],\n",
       " [2, 46, 8, 7, 825],\n",
       " [4, 252, 198, 9, 1],\n",
       " [15, 24, 826, 9, 8, 7],\n",
       " [1, 608, 2, 609, 46],\n",
       " [4, 252, 162, 8, 7],\n",
       " [2, 610, 46, 9, 1, 607],\n",
       " [2, 46, 66, 16, 413, 9, 8, 7],\n",
       " [252, 9, 198, 1, 6, 2, 46],\n",
       " [2, 46, 23, 9, 1],\n",
       " [4, 252, 189, 9, 1],\n",
       " [9, 1, 827, 2, 46],\n",
       " [17, 24, 143, 8, 7],\n",
       " [1, 6, 2, 609, 46, 41],\n",
       " [252, 198, 9, 1, 4],\n",
       " [8, 7, 608, 2, 610, 46],\n",
       " [2, 46, 66, 16, 828, 9, 1],\n",
       " [252, 162, 1, 2, 46, 41],\n",
       " [9, 198, 1, 6, 2, 46, 23],\n",
       " [252, 1],\n",
       " [294, 1],\n",
       " [829, 237],\n",
       " [39, 274, 3, 105, 2, 8, 7],\n",
       " [39, 611, 3, 10, 105, 2, 1, 111, 69],\n",
       " [39, 261, 3, 10, 418, 2, 8, 7],\n",
       " [39, 274, 830, 3, 105, 2, 1],\n",
       " [39, 612, 3, 2, 8, 7],\n",
       " [6, 39, 3, 10, 613, 105, 20, 2, 1],\n",
       " [39, 831, 3, 105, 113, 58, 2, 1],\n",
       " [39, 832, 274, 3, 10, 105, 111, 69, 2, 8, 7],\n",
       " [39, 261, 3, 614, 10, 418, 2, 1],\n",
       " [39, 274, 3, 10, 75, 487, 2, 1],\n",
       " [39, 615, 3, 10, 105, 346, 31, 2, 8, 7],\n",
       " [39, 23, 611, 3, 10, 105, 2, 1, 148],\n",
       " [6, 39, 3, 10, 418, 2, 1],\n",
       " [39, 274, 3, 105, 2, 1, 111, 69],\n",
       " [612, 3, 1, 6, 39, 41],\n",
       " [39, 261, 3, 10, 613, 20, 2, 1],\n",
       " [113, 58, 6, 39, 3, 105, 2, 1],\n",
       " [833, 39, 274, 3, 10, 105, 148, 2, 1],\n",
       " [39, 261, 3, 614, 10, 418, 2, 1],\n",
       " [6, 39, 3, 10, 307, 47, 20, 2, 1],\n",
       " [615, 6, 39, 3, 105, 346, 31, 2, 1],\n",
       " [274, 3, 1],\n",
       " [48, 81, 8, 7, 111, 69],\n",
       " [48, 10, 419, 218, 81, 1, 111, 69],\n",
       " [48, 616, 8, 7, 111, 69],\n",
       " [48, 81, 105, 2, 1, 148],\n",
       " [48, 10, 299, 81, 8, 7, 111, 69],\n",
       " [48, 488, 81, 1, 287, 148],\n",
       " [48, 617, 8, 2, 1, 111, 69],\n",
       " [48, 618, 619, 2, 8, 7],\n",
       " [48, 10, 620, 1, 218, 81, 148],\n",
       " [48, 81, 8, 7, 111, 69, 14, 249, 25, 419],\n",
       " [48, 81, 1, 148],\n",
       " [48, 10, 285, 81, 1, 111, 69],\n",
       " [48, 616, 9, 1, 148],\n",
       " [81, 105, 2, 1, 48, 41],\n",
       " [48, 488, 81, 1, 287, 69],\n",
       " [48, 617, 8, 2, 1, 111, 69],\n",
       " [48, 618, 619, 1, 148],\n",
       " [48, 10, 620, 1, 148, 218, 81],\n",
       " [81, 1, 148, 48, 14, 249, 25, 834],\n",
       " [48, 81, 1, 10, 419, 111, 69],\n",
       " [81, 1],\n",
       " [15, 328, 250, 8, 7],\n",
       " [25, 14, 15, 8, 7, 296],\n",
       " [4, 621, 622, 250, 8, 7],\n",
       " [15, 229, 623, 481, 9, 1],\n",
       " [4, 10, 835, 250, 8, 7],\n",
       " [15, 159, 1, 249, 229, 250],\n",
       " [48, 597, 8, 7, 14, 25, 296],\n",
       " [4, 117, 229, 111, 8, 7, 296],\n",
       " [15, 92, 624, 14, 159, 229, 1],\n",
       " [4, 155, 1, 30, 86, 83, 249, 420, 332, 277],\n",
       " [15, 1, 836, 469, 299, 169, 148],\n",
       " [17, 23, 328, 250, 1],\n",
       " [25, 14, 17, 229, 623, 1, 296],\n",
       " [4, 621, 622, 837, 9, 1],\n",
       " [48, 10, 596, 1, 14, 25, 250],\n",
       " [17, 159, 1, 249, 420, 332, 277],\n",
       " [17, 92, 624, 1, 2, 229, 250],\n",
       " [17, 838, 1, 188, 285, 169, 148],\n",
       " [328, 1],\n",
       " [348, 522, 328, 1],\n",
       " [328, 1, 17, 23],\n",
       " [4, 373, 8, 7, 839, 8, 55],\n",
       " [4, 22, 421, 8, 7, 331, 9, 55],\n",
       " [4, 10, 443, 1, 417, 2, 244, 8, 55],\n",
       " [4, 625, 840, 8, 7, 72, 8, 626],\n",
       " [841, 409, 1, 218, 163, 20, 331, 9, 55],\n",
       " [4, 22, 842, 10, 299, 373, 1, 2, 179, 83],\n",
       " [4, 10, 443, 8, 7, 33, 298, 479, 371],\n",
       " [4, 21, 627, 2, 1, 10, 628, 416, 9, 55],\n",
       " [15, 1, 629, 27, 8, 55, 2, 271, 118],\n",
       " [4, 373, 1, 30, 179, 56, 14, 246],\n",
       " [4, 625, 10, 843, 1, 151, 630, 276, 3],\n",
       " [4, 23, 421, 1, 331, 9, 55],\n",
       " [489, 1, 16, 417, 2, 244, 8, 55],\n",
       " [4, 10, 606, 1, 388, 72, 9, 626],\n",
       " [489, 71, 475, 1, 11, 20, 331, 9, 55],\n",
       " [4, 19, 373, 1, 2, 179, 83],\n",
       " [17, 1, 16, 29, 298, 479, 371, 331, 9, 55],\n",
       " [6, 21, 627, 4, 2, 1, 10, 12, 6, 2, 9, 55],\n",
       " [17, 1, 629, 36, 8, 55, 2, 330],\n",
       " [4, 19, 421, 1, 2, 179, 56, 14, 246],\n",
       " [489, 1, 102, 285, 151, 630, 276, 3],\n",
       " [421, 1],\n",
       " [373, 1],\n",
       " [5, 8, 7, 33, 844, 490],\n",
       " [48, 22, 119, 490, 72, 8, 7],\n",
       " [5, 6, 845, 846, 10, 631, 119, 1],\n",
       " [48, 22, 847, 490, 10, 175, 20, 2, 1],\n",
       " [5, 119, 1, 261, 10, 848, 2, 179, 403],\n",
       " [48, 22, 119, 1, 10, 33, 49, 2, 271, 118, 26, 77],\n",
       " [5, 6, 849, 26, 850, 10, 631, 90, 1],\n",
       " [15, 491, 119, 1, 2, 851, 179],\n",
       " [15, 8, 7, 247, 300, 230, 40],\n",
       " [4, 78, 1, 30, 247, 230, 40],\n",
       " [15, 1, 362, 3, 13, 300, 230, 40, 278],\n",
       " [4, 632, 8, 7, 30, 461, 321, 27, 230, 40],\n",
       " [15, 1, 852, 301, 30, 92, 853],\n",
       " [4, 633, 10, 205, 1, 2, 300, 230, 40, 278],\n",
       " [15, 1, 634, 27, 159, 301, 14, 635],\n",
       " [5, 67, 1, 636, 27, 637, 40, 333],\n",
       " [4, 155, 1, 30, 122, 3, 310, 207, 247, 464, 40, 278],\n",
       " [15, 8, 7, 638, 301, 180, 2, 300, 40, 111, 69],\n",
       " [5, 6, 21, 42, 2, 1, 13, 300, 230, 40, 278],\n",
       " [17, 1, 247, 230, 40],\n",
       " [4, 19, 288, 1, 11, 854, 230, 40, 278],\n",
       " [1, 855, 3, 17, 11, 300, 40, 278],\n",
       " [4, 632, 1, 11, 461, 321, 27, 159, 40],\n",
       " [17, 1, 176, 301, 30, 92, 856],\n",
       " [6, 633, 4, 19, 2, 1, 2, 300, 230, 40, 69],\n",
       " [1, 634, 17, 36, 301, 14, 635],\n",
       " [5, 67, 1, 284, 636, 27, 637, 40, 333],\n",
       " [4, 155, 1, 11, 193, 3, 207, 552, 464, 40, 278],\n",
       " [1, 29, 21, 42, 12, 11, 230, 40, 278],\n",
       " [4, 22, 28, 9, 10, 60, 2, 8, 7],\n",
       " [28, 4, 22, 10, 267, 124, 8, 7],\n",
       " [4, 22, 374, 14, 639, 10, 6, 2, 9, 1],\n",
       " [4, 28, 198, 10, 60, 51, 3, 2, 1],\n",
       " [4, 22, 28, 56, 10, 16, 422, 2, 8, 7],\n",
       " [4, 22, 79, 640, 3, 10, 60, 2, 9, 1],\n",
       " [4, 19, 28, 9, 10, 6, 2, 1],\n",
       " [1, 279, 28, 4, 19, 11, 3],\n",
       " [374, 14, 639, 2, 1, 6, 4, 19],\n",
       " [28, 198, 2, 9, 1, 4, 19, 41],\n",
       " [28, 56, 2, 1, 4, 19, 10, 16, 423, 3],\n",
       " [79, 640, 3, 2, 1, 6, 4, 19],\n",
       " [17, 28, 9, 1, 11, 64, 161],\n",
       " [4, 19, 45, 26, 163, 42, 10, 267, 1, 11, 3],\n",
       " [6, 28, 4, 2, 1, 11, 320, 64, 246],\n",
       " [28, 1],\n",
       " [4, 19, 28, 1],\n",
       " [15, 212, 156, 2, 1],\n",
       " [169, 4, 28, 156, 2, 8, 7],\n",
       " [5, 156, 2, 1, 492, 375, 83],\n",
       " [15, 641, 2, 156, 1, 122, 64, 642],\n",
       " [5, 156, 1, 643, 27, 301, 333],\n",
       " [15, 156, 2, 1, 125, 3, 30, 857],\n",
       " [5, 113, 54, 2, 1, 33, 156, 404],\n",
       " [15, 334, 14, 858, 156, 2, 9, 1],\n",
       " [15, 1, 493, 212, 14, 177, 2, 859],\n",
       " [5, 6, 156, 42, 13, 21, 120, 226, 2, 1],\n",
       " [17, 23, 212, 156, 2, 1],\n",
       " [28, 164, 2, 1, 312, 17, 41],\n",
       " [164, 2, 1, 284, 492, 375, 83, 452],\n",
       " [641, 2, 164, 1, 122, 642, 3, 12],\n",
       " [164, 2, 1, 643, 301, 333, 12, 23],\n",
       " [17, 155, 164, 1, 11, 193, 3, 860],\n",
       " [113, 54, 2, 1, 29, 164, 404, 12],\n",
       " [17, 334, 14, 861, 164, 2, 1],\n",
       " [1, 862, 212, 14, 177, 863, 17],\n",
       " [6, 164, 42, 11, 21, 120, 226, 2, 1, 12],\n",
       " [156, 1],\n",
       " [164, 1],\n",
       " [5, 1, 33, 68, 180],\n",
       " [5, 8, 7, 43, 68, 180],\n",
       " [5, 1, 33, 424, 644, 26, 376, 144],\n",
       " [15, 24, 165, 68, 180, 2, 1],\n",
       " [5, 6, 79, 68, 144, 13, 3, 1],\n",
       " [5, 1, 206, 104, 143, 376, 77, 216, 180],\n",
       " [5, 424, 68, 1, 60, 30, 645, 180],\n",
       " [15, 212, 14, 864, 646, 647, 180, 2, 68, 1],\n",
       " [1, 29, 68, 180, 12, 23],\n",
       " [6, 424, 644, 26, 376, 144, 2, 1, 12],\n",
       " [17, 24, 104, 68, 180, 2, 1],\n",
       " [3, 1, 16, 176, 79, 68, 144, 12],\n",
       " [1, 167, 104, 143, 376, 77, 216, 180, 12],\n",
       " [424, 68, 1, 60, 30, 645, 180, 12],\n",
       " [68, 144, 2, 1, 648, 17, 41],\n",
       " [17, 23, 24, 176, 865, 2, 1],\n",
       " [6, 12, 646, 647, 180, 10, 189, 2, 68, 1],\n",
       " [1, 279, 79, 866, 376, 144, 11, 3, 12],\n",
       " [68, 180, 1],\n",
       " [5, 1, 33, 28, 181, 26, 163, 302, 2, 30, 9],\n",
       " [5, 6, 181, 2, 30, 199, 9, 1],\n",
       " [5, 3, 1, 16, 413, 163, 302, 2, 30, 9],\n",
       " [15, 28, 181, 2, 8, 7],\n",
       " [5, 1, 43, 649, 151, 163, 302, 2, 9],\n",
       " [5, 6, 181, 42, 2, 127, 54, 2, 1],\n",
       " [15, 867, 650, 2, 181, 9, 1],\n",
       " [5, 181, 2, 1, 313, 868, 651, 20],\n",
       " [5, 60, 199, 302, 231, 51, 3, 2, 1],\n",
       " [5, 6, 494, 26, 425, 652, 2, 30, 426, 9, 1],\n",
       " [6, 181, 2, 30, 9, 1, 12, 23],\n",
       " [17, 28, 181, 2, 1],\n",
       " [1, 29, 649, 151, 163, 302, 2, 9, 12],\n",
       " [113, 54, 2, 1, 6, 869, 12],\n",
       " [650, 2, 181, 1, 870, 12, 41],\n",
       " [181, 2, 1, 313, 871, 653, 651, 20, 12],\n",
       " [6, 199, 302, 231, 11, 3, 2, 1],\n",
       " [2, 1, 6, 872, 26, 425, 652, 12, 23],\n",
       " [181, 1],\n",
       " [70, 873, 302, 237, 41],\n",
       " [6, 181, 202],\n",
       " [4, 19, 181, 2, 1],\n",
       " [4, 19, 425, 2, 1],\n",
       " [4, 19, 494, 2, 1],\n",
       " [6, 494, 202, 23, 2, 1],\n",
       " [6, 425, 202, 2, 1],\n",
       " [5, 1, 33, 45, 253, 26, 45, 120, 213, 13, 3],\n",
       " [5, 1, 43, 45, 253, 51, 3],\n",
       " [5, 6, 45, 120, 213, 2, 9, 1],\n",
       " [5, 3, 16, 377, 45, 253, 2, 1],\n",
       " [5, 1, 33, 28, 45, 161, 213],\n",
       " ...]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize the data (Tokenisasi Data)\n",
    "tokenizer = Tokenizer(num_words=2000)\n",
    "tokenizer.fit_on_texts(data['patterns'])\n",
    "train = tokenizer.texts_to_sequences(data['patterns'])\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LfEpFf0hPOUZ",
   "metadata": {
    "id": "LfEpFf0hPOUZ"
   },
   "source": [
    "## **Padding**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5BQdPUTNvS1t",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5BQdPUTNvS1t",
    "outputId": "cb11934b-5cae-428f-dd99-5077e3db2e11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0 ...   0   0 697]\n",
      " [  0   0   0 ...   0 513 698]\n",
      " [  0   0   0 ...   0   0 699]\n",
      " ...\n",
      " [  0   0   0 ...  81   1 148]\n",
      " [  0   0   0 ...  81   1  48]\n",
      " [  0   0   0 ... 976   2   1]]\n"
     ]
    }
   ],
   "source": [
    "# Melakukan proses padding pada data\n",
    "x_train = pad_sequences(train)\n",
    "# Menampilkan hasil padding\n",
    "print(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1Khg-ygkb0nD",
   "metadata": {
    "id": "1Khg-ygkb0nD"
   },
   "source": [
    "Hasil setelah padding adalah setiap sequence memiliki panjang yang sama. Padding dapat melakukan ini dengan menambahkan 0 secara default pada awal sequence yang lebih pendek."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qY0vxxwBPeJC",
   "metadata": {
    "id": "qY0vxxwBPeJC"
   },
   "source": [
    "## **Encoding Text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "sczq--IpTYWa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sczq--IpTYWa",
    "outputId": "954c1db5-02b4-4082-8885-10314a414d92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24 24 24 ... 88 88 88]\n"
     ]
    }
   ],
   "source": [
    "# Melakukan konversi data label tags dengan encoding\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(data['tags'])\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbtBZXFvgvCB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dbtBZXFvgvCB",
    "outputId": "070b4960-6a05-4a00-be91-305a81075b32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "# Melihat hasil input pada data teks\n",
    "input_shape = x_train.shape[1]\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "310y6oNLhuzv",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "310y6oNLhuzv",
    "outputId": "abcd311f-e8bf-4468-f1b8-bbfd49561f9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique words :  976\n",
      "output length:  91\n"
     ]
    }
   ],
   "source": [
    "# Melakukan definisi tiap kalimat dan kata pada data teks\n",
    "vocabulary = len(tokenizer.word_index)\n",
    "print(\"number of unique words : \", vocabulary)\n",
    "\n",
    "# Melakukan pemeriksaan pada data output label teks\n",
    "output_length = le.classes_.shape[0]\n",
    "print(\"output length: \", output_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AInHhmVGict2",
   "metadata": {
    "id": "AInHhmVGict2"
   },
   "source": [
    "**Input length** dan **output length** terlihat sangat jelas hasilnya. Mereka adalah untuk bentuk input dan bentuk output dari data train atau latih yang akan diproses pada algoritma LSTM yang akan dilatih.\n",
    "\n",
    "**Vocabulary Size** adalah untuk lapisan penyematan untuk membuat representasi vektor unik untuk setiap kata."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1LxIElYjQbB7",
   "metadata": {
    "id": "1LxIElYjQbB7"
   },
   "source": [
    "## **Save Model Words & Classes**\n",
    "\n",
    "Setelah dilakukan pemrosesan teks yang dilakukan lima tahap maka kita bisa simpan model pemrosesan teks tersebut dengan menggunakan format pickle.\n",
    "\n",
    "Hal ini biasanya digunakan untuk membuat hubungan model yang telah dilatih dengan model pemrosesan teks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "wYV77QFbQVLP",
   "metadata": {
    "id": "wYV77QFbQVLP"
   },
   "outputs": [],
   "source": [
    "# Simpan hasil pemrosesan teks dengan menggunakan pickle\n",
    "pickle.dump(words, open('words.pkl','wb'))\n",
    "pickle.dump(classes, open('classes.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dY9COWCwexgZ",
   "metadata": {
    "id": "dY9COWCwexgZ"
   },
   "source": [
    "## **Save Label Encoder & Tokenizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "saM3QTSjewR4",
   "metadata": {
    "id": "saM3QTSjewR4"
   },
   "outputs": [],
   "source": [
    "pickle.dump(le, open('le.pkl','wb'))\n",
    "pickle.dump(tokenizer, open('tokenizers.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2XBG3_reh2KY",
   "metadata": {
    "id": "2XBG3_reh2KY"
   },
   "outputs": [],
   "source": [
    "# Creating the model (Membuat Modelling)\n",
    "i = Input(shape=(input_shape,)) # Layer Input\n",
    "x = Embedding(vocabulary+1,10)(i) # Layer Embedding\n",
    "x = LSTM(10, return_sequences=True, recurrent_dropout=0.2)(x) # Layer Long Short Term Memory\n",
    "x = Flatten()(x) # Layer Flatten\n",
    "x = Dense(output_length, activation=\"softmax\")(x) # Layer Dense\n",
    "model  = Model(i,x) # Model yang telah disusun dari layer Input sampai layer Output\n",
    "\n",
    "# Compiling the model (Kompilasi Model)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "SO1blkS7ZzuH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "SO1blkS7ZzuH",
    "outputId": "40ac3df7-15dd-44f0-a9b5-55119c0db233"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) for `plot_model` to work.\n"
     ]
    }
   ],
   "source": [
    "# Visualization Plot Architecture Model (Visualisasi Plot Arsitektur Model)\n",
    "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4hab_JHoopQI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "4hab_JHoopQI",
    "outputId": "ae341249-b55b-46c9-a7af-fbcb859693c7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,770</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">840</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">140</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">91</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,831</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m10\u001b[0m)         │         \u001b[38;5;34m9,770\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m10\u001b[0m)         │           \u001b[38;5;34m840\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m140\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m91\u001b[0m)             │        \u001b[38;5;34m12,831\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,441</span> (91.57 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m23,441\u001b[0m (91.57 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,441</span> (91.57 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m23,441\u001b[0m (91.57 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Menampilkan parameter pada model LSTM\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "AHtOlCb8kGgZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AHtOlCb8kGgZ",
    "outputId": "d69309b5-4fd4-48ce-84b0-54a731dd8226"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0134 - loss: 4.5091\n",
      "Epoch 2/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0349 - loss: 4.4810\n",
      "Epoch 3/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0511 - loss: 4.4004\n",
      "Epoch 4/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1029 - loss: 4.1890\n",
      "Epoch 5/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1256 - loss: 3.9386\n",
      "Epoch 6/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1672 - loss: 3.6787\n",
      "Epoch 7/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2218 - loss: 3.3779\n",
      "Epoch 8/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2611 - loss: 3.1733\n",
      "Epoch 9/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3344 - loss: 2.9019\n",
      "Epoch 10/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3800 - loss: 2.6892\n",
      "Epoch 11/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4735 - loss: 2.4978\n",
      "Epoch 12/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4890 - loss: 2.3437\n",
      "Epoch 13/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5332 - loss: 2.1416\n",
      "Epoch 14/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5679 - loss: 1.9705\n",
      "Epoch 15/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6022 - loss: 1.8624\n",
      "Epoch 16/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6348 - loss: 1.6918\n",
      "Epoch 17/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6784 - loss: 1.5565\n",
      "Epoch 18/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7150 - loss: 1.4464\n",
      "Epoch 19/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7308 - loss: 1.3430\n",
      "Epoch 20/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7590 - loss: 1.2730\n",
      "Epoch 21/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7861 - loss: 1.1346\n",
      "Epoch 22/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8001 - loss: 1.0881\n",
      "Epoch 23/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8279 - loss: 0.9878\n",
      "Epoch 24/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8402 - loss: 0.9400\n",
      "Epoch 25/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8487 - loss: 0.8690\n",
      "Epoch 26/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8657 - loss: 0.8142\n",
      "Epoch 27/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8879 - loss: 0.7205\n",
      "Epoch 28/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8819 - loss: 0.7222\n",
      "Epoch 29/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8838 - loss: 0.6950\n",
      "Epoch 30/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8980 - loss: 0.6516\n",
      "Epoch 31/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9163 - loss: 0.5992\n",
      "Epoch 32/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9172 - loss: 0.5614\n",
      "Epoch 33/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9363 - loss: 0.5170\n",
      "Epoch 34/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9162 - loss: 0.5370\n",
      "Epoch 35/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9448 - loss: 0.4575\n",
      "Epoch 36/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9506 - loss: 0.4417\n",
      "Epoch 37/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9572 - loss: 0.4061\n",
      "Epoch 38/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9484 - loss: 0.4090\n",
      "Epoch 39/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9568 - loss: 0.3661\n",
      "Epoch 40/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9684 - loss: 0.3367\n",
      "Epoch 41/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9562 - loss: 0.3560\n",
      "Epoch 42/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9644 - loss: 0.3406\n",
      "Epoch 43/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9647 - loss: 0.3125\n",
      "Epoch 44/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9778 - loss: 0.2830\n",
      "Epoch 45/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9774 - loss: 0.2753\n",
      "Epoch 46/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9670 - loss: 0.2849\n",
      "Epoch 47/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9806 - loss: 0.2683\n",
      "Epoch 48/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9731 - loss: 0.2723\n",
      "Epoch 49/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9821 - loss: 0.2319\n",
      "Epoch 50/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9806 - loss: 0.2346\n",
      "Epoch 51/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9792 - loss: 0.2196\n",
      "Epoch 52/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9812 - loss: 0.2212\n",
      "Epoch 53/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9861 - loss: 0.1858\n",
      "Epoch 54/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.2001\n",
      "Epoch 55/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9846 - loss: 0.1944\n",
      "Epoch 56/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9879 - loss: 0.1830\n",
      "Epoch 57/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9862 - loss: 0.1733\n",
      "Epoch 58/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9869 - loss: 0.1575\n",
      "Epoch 59/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9900 - loss: 0.1540\n",
      "Epoch 60/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9916 - loss: 0.1549\n",
      "Epoch 61/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9927 - loss: 0.1433\n",
      "Epoch 62/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9909 - loss: 0.1389\n",
      "Epoch 63/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9912 - loss: 0.1388\n",
      "Epoch 64/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9971 - loss: 0.1249\n",
      "Epoch 65/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9938 - loss: 0.1247\n",
      "Epoch 66/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9940 - loss: 0.1136\n",
      "Epoch 67/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9925 - loss: 0.1233\n",
      "Epoch 68/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9938 - loss: 0.1090\n",
      "Epoch 69/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9968 - loss: 0.1105\n",
      "Epoch 70/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9944 - loss: 0.1110\n",
      "Epoch 71/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9966 - loss: 0.0953\n",
      "Epoch 72/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9952 - loss: 0.1007\n",
      "Epoch 73/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9946 - loss: 0.0976\n",
      "Epoch 74/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9951 - loss: 0.0997\n",
      "Epoch 75/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9967 - loss: 0.0880\n",
      "Epoch 76/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9960 - loss: 0.0908\n",
      "Epoch 77/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9967 - loss: 0.0853\n",
      "Epoch 78/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9985 - loss: 0.0857\n",
      "Epoch 79/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9986 - loss: 0.0794\n",
      "Epoch 80/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 0.0769\n",
      "Epoch 81/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9988 - loss: 0.0759\n",
      "Epoch 82/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9990 - loss: 0.0692\n",
      "Epoch 83/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9991 - loss: 0.0656\n",
      "Epoch 84/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0656\n",
      "Epoch 85/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9981 - loss: 0.0666\n",
      "Epoch 86/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9988 - loss: 0.0540\n",
      "Epoch 87/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9992 - loss: 0.0649\n",
      "Epoch 88/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0591\n",
      "Epoch 89/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 0.0597\n",
      "Epoch 90/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0539\n",
      "Epoch 91/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 0.0478\n",
      "Epoch 92/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0553\n",
      "Epoch 93/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9985 - loss: 0.0507\n",
      "Epoch 94/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0501\n",
      "Epoch 95/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0483\n",
      "Epoch 96/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0432\n",
      "Epoch 97/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0463\n",
      "Epoch 98/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0449\n",
      "Epoch 99/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0377\n",
      "Epoch 100/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0378\n",
      "Epoch 101/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0348\n",
      "Epoch 102/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0411\n",
      "Epoch 103/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0353\n",
      "Epoch 104/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0355\n",
      "Epoch 105/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0350\n",
      "Epoch 106/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0344\n",
      "Epoch 107/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0326\n",
      "Epoch 108/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0267\n",
      "Epoch 109/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0305\n",
      "Epoch 110/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0275\n",
      "Epoch 111/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0282\n",
      "Epoch 112/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0272\n",
      "Epoch 113/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0257\n",
      "Epoch 114/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0274\n",
      "Epoch 115/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0246\n",
      "Epoch 116/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0252\n",
      "Epoch 117/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0228\n",
      "Epoch 118/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0254\n",
      "Epoch 119/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0221\n",
      "Epoch 120/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0216\n",
      "Epoch 121/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0200\n",
      "Epoch 122/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0208\n",
      "Epoch 123/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0190\n",
      "Epoch 124/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0179\n",
      "Epoch 125/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0185\n",
      "Epoch 126/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0184\n",
      "Epoch 127/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0168\n",
      "Epoch 128/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0183\n",
      "Epoch 129/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0166\n",
      "Epoch 130/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0154\n",
      "Epoch 131/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0171\n",
      "Epoch 132/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0143\n",
      "Epoch 133/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0144\n",
      "Epoch 134/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0154\n",
      "Epoch 135/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0128\n",
      "Epoch 136/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0125\n",
      "Epoch 137/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0131\n",
      "Epoch 138/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0123\n",
      "Epoch 139/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0137\n",
      "Epoch 140/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0123\n",
      "Epoch 141/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0122\n",
      "Epoch 142/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0117\n",
      "Epoch 143/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0116\n",
      "Epoch 144/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0121\n",
      "Epoch 145/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0113\n",
      "Epoch 146/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0120\n",
      "Epoch 147/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0106\n",
      "Epoch 148/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0109\n",
      "Epoch 149/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0092\n",
      "Epoch 150/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0090\n",
      "Epoch 151/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0092\n",
      "Epoch 152/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0076\n",
      "Epoch 153/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0092\n",
      "Epoch 154/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0085\n",
      "Epoch 155/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0085\n",
      "Epoch 156/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0085\n",
      "Epoch 157/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0076\n",
      "Epoch 158/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0077\n",
      "Epoch 159/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0071\n",
      "Epoch 160/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0075\n",
      "Epoch 161/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0069\n",
      "Epoch 162/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0071\n",
      "Epoch 163/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0069\n",
      "Epoch 164/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0061\n",
      "Epoch 165/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0059\n",
      "Epoch 166/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0054\n",
      "Epoch 167/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0061\n",
      "Epoch 168/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0054\n",
      "Epoch 169/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0053\n",
      "Epoch 170/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0054\n",
      "Epoch 171/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0050\n",
      "Epoch 172/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0048\n",
      "Epoch 173/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0052\n",
      "Epoch 174/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0048\n",
      "Epoch 175/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0046\n",
      "Epoch 176/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0049\n",
      "Epoch 177/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0043\n",
      "Epoch 178/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0045\n",
      "Epoch 179/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0041\n",
      "Epoch 180/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0043\n",
      "Epoch 181/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0040\n",
      "Epoch 182/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0036\n",
      "Epoch 183/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0039\n",
      "Epoch 184/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0034\n",
      "Epoch 185/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0034\n",
      "Epoch 186/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0036\n",
      "Epoch 187/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0034\n",
      "Epoch 188/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0032\n",
      "Epoch 189/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0031\n",
      "Epoch 190/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0039\n",
      "Epoch 191/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0032\n",
      "Epoch 192/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0030\n",
      "Epoch 193/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0030\n",
      "Epoch 194/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0029\n",
      "Epoch 195/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0029\n",
      "Epoch 196/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0026\n",
      "Epoch 197/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0025\n",
      "Epoch 198/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0024\n",
      "Epoch 199/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0025\n",
      "Epoch 200/200\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0026\n"
     ]
    }
   ],
   "source": [
    "# Training the model (Melatih model data sampai 300 kali)\n",
    "train = model.fit(x_train, y_train, epochs=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PpFwQ9gWmWtk",
   "metadata": {
    "id": "PpFwQ9gWmWtk"
   },
   "source": [
    "# **Save The Model (Simpan Model)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "MxdDHujDmaC0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MxdDHujDmaC0",
    "outputId": "1ea42bc5-3f58-4143-f4f3-bd1938d89926"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Created Successfully!\n"
     ]
    }
   ],
   "source": [
    "# Simpan model dalam bentuk format file .h5 atau .pkl (pickle)\n",
    "model.save('model_lstm.h5')\n",
    "\n",
    "print('Model Created Successfully!')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
